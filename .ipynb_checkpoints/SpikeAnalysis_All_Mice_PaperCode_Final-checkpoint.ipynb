{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# This notebook will analyze raw spike data from recorded sessions in the experiments outlined in Rolon-Martinez, et. al (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions and Plotting Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import packages you will need for running this script ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MaxNLocator, AutoMinorLocator, LinearLocator, FormatStrFormatter\n",
    "import scipy as scipy\n",
    "from scipy import io\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy import stats\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "from datetime import datetime\n",
    "import cmasher as cmr\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import linear_model\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Global Plotting Parameters\n",
    "\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = 'Arial'\n",
    "mpl.rcParams['font.size'] = 8\n",
    "mpl.rcParams.update({'mathtext.default':  'regular' })\n",
    "# mpl.rcParams['figure.figsize']: (0.67,0.5)\n",
    "mpl.rcParams['figure.titlesize'] = 8\n",
    "mpl.rcParams['figure.autolayout']: True\n",
    "mpl.rcParams['figure.constrained_layout.use'] = True\n",
    "    \n",
    "mpl.rcParams['savefig.dpi'] = 600\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "mpl.rcParams['savefig.pad_inches'] = 0\n",
    "mpl.rcParams['savefig.transparent'] = True\n",
    "\n",
    "mpl.rcParams['axes.linewidth'] = 0.5\n",
    "mpl.rcParams['axes.labelsize'] = 8\n",
    "mpl.rcParams['axes.labelpad'] = 2\n",
    "mpl.rcParams['xaxis.labellocation'] = 'center'\n",
    "mpl.rcParams['yaxis.labellocation'] = 'center'\n",
    "mpl.rcParams['axes.titlesize'] = 8\n",
    "mpl.rcParams['axes.titlepad'] = 4\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "mpl.rcParams['legend.loc']='upper left'\n",
    "mpl.rcParams['legend.frameon']= False\n",
    "mpl.rcParams['legend.fontsize']= 6\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "mpl.rcParams['xtick.labelsize']= 6\n",
    "mpl.rcParams['ytick.labelsize']= 6\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 2\n",
    "mpl.rcParams['xtick.major.width'] = .5\n",
    "mpl.rcParams['ytick.major.size'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = .5\n",
    "mpl.rcParams['xtick.major.pad'] = 1\n",
    "mpl.rcParams['ytick.major.pad'] = 1\n",
    "\n",
    "mpl.rcParams['xtick.minor.size'] = 1\n",
    "mpl.rcParams['xtick.minor.width'] = .5\n",
    "mpl.rcParams['ytick.minor.size'] = 1\n",
    "mpl.rcParams['ytick.minor.width'] = .5\n",
    "mpl.rcParams['xtick.minor.pad'] = 1\n",
    "mpl.rcParams['ytick.minor.pad'] = 1\n",
    "\n",
    "_new_black = '#373737'\n",
    "mpl.rcParams['lines.color'] = _new_black\n",
    "mpl.rcParams['patch.edgecolor'] = _new_black\n",
    "mpl.rcParams['patch.force_edgecolor'] = False\n",
    "mpl.rcParams['boxplot.flierprops.color'] = _new_black\n",
    "mpl.rcParams['boxplot.flierprops.markeredgecolor'] = _new_black\n",
    "mpl.rcParams['boxplot.boxprops.color'] = _new_black\n",
    "mpl.rcParams['boxplot.whiskerprops.color'] = _new_black\n",
    "mpl.rcParams['boxplot.capprops.color'] = _new_black\n",
    "mpl.rcParams['boxplot.capprops.linewidth'] = 0.5\n",
    "mpl.rcParams['text.color'] = _new_black\n",
    "mpl.rcParams['axes.edgecolor'] = _new_black\n",
    "mpl.rcParams['axes.labelcolor'] = _new_black\n",
    "mpl.rcParams['xtick.color'] = _new_black\n",
    "mpl.rcParams['ytick.color'] = _new_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions for running data analysis ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(data_loc, subfolder, filename):\n",
    "    return np.load(os.path.join(data_loc, subfolder, filename))\n",
    "\n",
    "def read_sync_messages(data_loc):\n",
    "    sync_messages_path = os.path.join(data_loc, 'sync_messages.txt')\n",
    "    try:\n",
    "        with open(sync_messages_path, 'r') as file:\n",
    "            for last_line in file:\n",
    "                pass\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {sync_messages_path} not found.\")\n",
    "        return None, None\n",
    "    \n",
    "    start_time, sample_rate = map(int, last_line.split('@'))\n",
    "    sample_rate = sample_rate[:-2]  # Remove Hz from sample rate string\n",
    "    return start_time, sample_rate\n",
    "\n",
    "def convert_to_seconds(samples, start_time, fs):\n",
    "    return (samples - start_time) / fs\n",
    "\n",
    "def select_block_events(events_timestamps, event_states, block_start, block_end=None):\n",
    "    if block_end is None:\n",
    "        indices = events_timestamps > block_start\n",
    "    else:\n",
    "        indices = (events_timestamps > block_start) & (events_timestamps < block_end)\n",
    "    return events_timestamps[indices], event_states[indices]\n",
    "\n",
    "def load_cluster_info(data_loc):\n",
    "    clust_info = pd.read_csv(os.path.join(data_loc, 'cluster_info.tsv'), delimiter='\\t')\n",
    "    return clust_info[clust_info.group != 'noise']\n",
    "\n",
    "def load_mean_waveforms(data_loc):\n",
    "    mean_waves = loadmat(os.path.join(data_loc, 'mean_waveforms.mat'))\n",
    "    ycoords = mean_waves['chanMap']['ycoords'][0][0][0]\n",
    "    mn = np.squeeze(mean_waves['mn']) - 1  # Adjusting MATLAB's 1-based indexing\n",
    "    clust_depth = ycoords[mn]\n",
    "    max_depth = np.max(mean_waves['chanMap']['ycoords'][0][0][0])\n",
    "    clust_depth = np.int32(clust_depth) - np.int32(max_depth)\n",
    "    return clust_depth\n",
    "\n",
    "def get_events(data_loc):\n",
    "    msg_text = load_npy_files(data_loc, 'messages', 'text.npy')\n",
    "    msg_sample = load_npy_files(data_loc, 'messages', 'timestamps.npy')\n",
    "    ev_state = load_npy_files(data_loc, 'events', 'channel_states.npy')\n",
    "    ev_sample = load_npy_files(data_loc, 'events', 'timestamps.npy')\n",
    "    start_time, fs = read_sync_messages(data_loc)\n",
    "    \n",
    "    if start_time is None or fs is None:\n",
    "        return None\n",
    "    \n",
    "    ev_ts = convert_to_seconds(ev_sample, start_time, fs)\n",
    "    msg_ts = convert_to_seconds(msg_sample, start_time, fs)\n",
    "    \n",
    "    print(*msg_text, sep='\\n')\n",
    "    print(\"Total number of blocks:\", len(msg_ts))\n",
    "    block_start_id = int(input(\"Indicate Block Start here (remember python syntax where 0 = 1): \"))\n",
    "    block_start = msg_ts[block_start_id]\n",
    "    \n",
    "    if block_start_id + 1 >= len(msg_ts):\n",
    "        block_end = None\n",
    "    else:\n",
    "        block_end = msg_ts[block_start_id + 1]\n",
    "    \n",
    "    block_ev_ts, block_ev_state = select_block_events(ev_ts, ev_state, block_start, block_end)\n",
    "    \n",
    "    spikes = load_npy_files(data_loc, '', 'spike_times.npy') / fs\n",
    "    clust = load_npy_files(data_loc, '', 'spike_clusters.npy')\n",
    "    clust_info = load_cluster_info(data_loc)\n",
    "    clust_depth = load_mean_waveforms(data_loc)\n",
    "    \n",
    "    stimulus_on = block_ev_ts[block_ev_state == 1][1:]  # Assuming the first event is not a stimulus onset\n",
    "    stimulus_off = block_ev_ts[block_ev_state == -1][1:]  # Assuming the first event is not a stimulus offset\n",
    "    \n",
    "    return ev_state, ev_ts, msg_ts, block_ev_ts, stimulus_on, spikes, clust, clust_depth, clust_info, stimulus_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function applies a smoothing guassian filter to your data\n",
    "def SmoothGauss(X, M):\n",
    "    if X.ndim != 1:\n",
    "        raise ValueError(\"X must be a 1D array.\")\n",
    "    \n",
    "    sigma = M ** 0.5\n",
    "    G = np.arange(-M, M+1)\n",
    "    F = np.exp(-G**2 / ((2 * sigma)**2))\n",
    "    F /= np.sum(F)\n",
    "    Y = np.convolve(X, F, mode='full')\n",
    "    \n",
    "    start_index = M\n",
    "    end_index = start_index + len(X)\n",
    "    Y = Y[start_index:end_index]\n",
    "    \n",
    "    correction_start = np.sum(F) / (np.sum(F[:M]) + np.cumsum(F[M:M*2]))\n",
    "    correction_end = np.sum(F) / (np.sum(F[:M]) + np.cumsum(F[M:M*2])[::-1])\n",
    "    \n",
    "    Y[:M] *= correction_start\n",
    "    Y[-M:] *= correction_end\n",
    "    \n",
    "    return Y\n",
    "\n",
    "\n",
    "# This function extracts spikes and returns your raster, trials and psth variable:\n",
    "def spike_data(spikes, stimulusOnset, edges, smVar):\n",
    "    raster = []\n",
    "    trials = []\n",
    "    psth = np.empty(([len(stimulusOnset), len(edges)-1]))\n",
    "    psth_S = np.empty(([len(stimulusOnset), len(edges)-1]))\n",
    "    \n",
    "    for s, stim in enumerate (stimulusOnset):\n",
    "        \n",
    "        spks = spikes - stim\n",
    "        \n",
    "        psth[s,:], _ = np.histogram(spks, bins=edges)\n",
    "        psth[s,:] = psth[s,:]/np.diff(edges).mean()\n",
    "        psth_S[s,:] = SmoothGauss(psth[s,:],smVar)\n",
    "        \n",
    "        spks = spks[(spks > edges[0]) & (spks < edges[-1])]\n",
    "        raster.extend(spks)\n",
    "        trials.extend(np.ones(len(spks))*(s+1))\n",
    "        \n",
    "    return raster, trials, psth, psth_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stim_info(stim_loc, file_name, extract_fields=None):\n",
    "    \"\"\"\n",
    "    Load stimulus information from a MATLAB file, handling multi-dimensional arrays appropriately.\n",
    "\n",
    "    Parameters:\n",
    "    - stim_loc: The directory where the stimulus file is located.\n",
    "    - file_name: The name of the MATLAB file containing the stimulus information.\n",
    "    - extract_fields: Optional list of fields to extract from the stimulus information.\n",
    "                      If None, all fields are extracted.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing the requested stimulus information, or all information if extract_fields is None.\n",
    "    - The name of the file.\n",
    "    \"\"\"\n",
    "    full_path = os.path.join(stim_loc, file_name)\n",
    "    try:\n",
    "        file = loadmat(full_path, appendmat=True)\n",
    "        stim_inf = file['stimInfo'][0, 0]\n",
    "        stim_info = {}\n",
    "        \n",
    "        # If no specific fields are requested, extract all.\n",
    "        if extract_fields is None:\n",
    "            extract_fields = stim_inf.dtype.names\n",
    "        \n",
    "        for field in extract_fields:\n",
    "            if field in stim_inf.dtype.names:\n",
    "                # Handling multi-dimensional arrays without converting to scalar\n",
    "                value = stim_inf[field]\n",
    "                if value.size == 1:\n",
    "                    stim_info[field] = value.item()  # For single elements, convert to scalar\n",
    "                else:\n",
    "                    stim_info[field] = value  # Keep as array for multi-dimensional data\n",
    "            else:\n",
    "                print(f\"Warning: '{field}' not found in stimulus information.\")\n",
    "        \n",
    "        return stim_info, file_name\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{full_path}' not found.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_stimulus_info(stim_loc, main_stim_file, laser_stim_file, nreps, nreps_laser, extract_fields=None):\n",
    "    main_stim_info, _ = load_stim_info(stim_loc, main_stim_file + '.mat', extract_fields)\n",
    "    if main_stim_info is None:\n",
    "        print(f\"Failed to load main stimulus information from {main_stim_file}\")\n",
    "        return None\n",
    "\n",
    "    laser_stim_info, _ = load_stim_info(stim_loc, laser_stim_file + '.mat', extract_fields)\n",
    "    if laser_stim_info is None:\n",
    "        print(f\"Failed to load laser stimulus information from {laser_stim_file}\")\n",
    "        return None\n",
    "\n",
    "    # Direct extraction of necessary information without duplication\n",
    "    return {\n",
    "        \"ITI_laser\": laser_stim_info.get('ITI', None),\n",
    "        \"laserOnlyDur\": laser_stim_info.get('laserDur', None),\n",
    "        \"ITI\": main_stim_info.get('ITI', None),\n",
    "        \"laserDur\": main_stim_info.get('laserDur', None),\n",
    "        \"tDur\": main_stim_info.get('tDur', None),\n",
    "        \"trialOrder_main\": main_stim_info.get('trialOrder', [])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probe_data(excel_path, cell_type, virus):\n",
    "    # Assuming each sheet corresponds to a different cell type or there's a naming pattern\n",
    "    sheet_name = f'{cell_type}_{virus}_Depths'\n",
    "    return pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "\n",
    "def load_and_concatenate_npz(directory, stim):\n",
    "    files = sorted(glob(os.path.join(directory, f'*{stim}.npz')))\n",
    "    all_data = [np.load(f, allow_pickle=True) for f in files]\n",
    "    \n",
    "    fullpsth = np.concatenate([data['allPSTH'] for data in all_data if 'allPSTH' in data.files], axis=2)\n",
    "    fullpsthS = np.concatenate([data['allPSTH_S'] for data in all_data if 'allPSTH_S' in data.files], axis=2)\n",
    "    \n",
    "    clustdepth = []\n",
    "    rasters = []\n",
    "    trials = []\n",
    "    spikesortind = []\n",
    "    session_mapping = {}\n",
    "    current_index = 0\n",
    "    \n",
    "    for idx, data in enumerate(all_data):\n",
    "        session_id = os.path.basename(files[idx]).split(' ')[2]  # Adjust according to filename format\n",
    "        if 'clustDepth' in data.files and data['clustDepth'].size > 0:\n",
    "            clust_depth_data = [(depth, session_id) for depth in data['clustDepth'].tolist()]\n",
    "            clustdepth.extend(clust_depth_data)\n",
    "            \n",
    "            session_mapping[session_id] = (current_index, current_index + len(clust_depth_data))\n",
    "            current_index += len(clust_depth_data)\n",
    "        \n",
    "        if 'rasters' in data.files and data['rasters'].size > 0:\n",
    "            rasters.extend(data['rasters'].tolist())\n",
    "        \n",
    "        if 'trials' in data.files and data['trials'].size > 0:\n",
    "            trials.extend(data['trials'].tolist())\n",
    "        \n",
    "        if 'spikeSortI' in data.files and data['spikeSortI'].size > 0:\n",
    "            spikesortind.extend(data['spikeSortI'].tolist())\n",
    "    \n",
    "    clustdepth = np.array(clustdepth, dtype=object)\n",
    "    rasters = np.array(rasters, dtype=object)\n",
    "    trials = np.array(trials, dtype=object)\n",
    "    spikesortind = np.array(spikesortind, dtype=object) if spikesortind else None\n",
    "    \n",
    "    return fullpsth, fullpsthS, clustdepth, rasters, trials, spikesortind, session_mapping\n",
    "\n",
    "\n",
    "def summarize_data(rasters, spikesortind, clustdepth, fullpsth, fullpsthS, fullpsth_L, fullpsthS_L):\n",
    "    \"\"\"\n",
    "    Summarize the dimensions and shapes of key experimental data arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - Rasters: Raster plot data.\n",
    "    - SpikeSortInd: Spike sorting index.\n",
    "    - Clust_Depth: Cluster depth information.\n",
    "    - FullPSTH: Full peri-stimulus time histogram.\n",
    "    \"\"\"\n",
    "    print(\"Data Summary:\")\n",
    "    print(\"-------------\")\n",
    "    print(f\"Length of Rasters: {len(rasters)}\")\n",
    "    print(f\"Length of SpikeSortInd: {len(spikesortind)}\")\n",
    "    print(f\"Length of Clust_Depth: {len(clustdepth)}\")\n",
    "    print(f\"Shape of FullPSTH: {fullpsth.shape}\")\n",
    "    print(f\"Shape of Smoothed FullPSTH: {fullpsthS.shape}\")\n",
    "    print(f\"Shape of FullPSTH_Laser: {fullpsth_L.shape}\")\n",
    "    print(f\"Shape of Smoothed FullPSTH_Laser: {fullpsthS_L.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_data(data_path, main_stim_file, data_path_laser, laser_stim_file, stim_loc, nreps, nreps_laser):\n",
    "    binSize = .002  \n",
    "    edges = np.arange(-.050, .20, binSize)\n",
    "    time = edges[:-1]\n",
    "\n",
    "    FullPSTH, FullPSHT_S, Clust_Depth, Rasters, Trials, SpikeSortInd, Session_Map = load_and_concatenate_npz(data_path,\n",
    "                                                                                                             main_stim_file.replace(\".mat\", \"\"))\n",
    "    \n",
    "    FullPSTH_Laser, FullPSHT_S_Laser, Clust_Depth_laser, Rasters_laser, Trials, SpikeSortInd_laser, Session_Map_Laser = load_and_concatenate_npz(data_path_laser, laser_stim_file.replace(\".mat\", \"\"))\n",
    "    \n",
    "    stim_info = get_stimulus_info(stim_loc, main_stim_file, laser_stim_file, nreps, nreps_laser)\n",
    "    \n",
    "    # Repetition of trialOrder calculation is now removed and directly fetched from stim_info\n",
    "    trialOrder = np.matlib.repmat(stim_info['trialOrder_main'], nreps, 1)\n",
    "    ITI, ITI_laser = stim_info['ITI'], stim_info['ITI_laser']\n",
    "    laserDur, laserOnlyDur = stim_info['laserDur'], stim_info['laserOnlyDur']\n",
    "    tDur = stim_info['tDur']\n",
    "\n",
    "    \n",
    "    return FullPSTH, FullPSHT_S, Clust_Depth, Rasters, Trials, SpikeSortInd, FullPSTH_Laser, FullPSHT_S_Laser, trialOrder, ITI, ITI_laser, laserDur, laserOnlyDur, tDur, binSize, edges, time , Session_Map, Session_Map_Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ismember(A, B):\n",
    "    A = np.asarray(A).astype(int)\n",
    "    B = np.asarray(B).astype(int)\n",
    "    res = np.zeros(A.shape)\n",
    "    for i in np.unique(A):\n",
    "        res[A == i] = np.argwhere(B == i).squeeze()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cluster_depths_to_real_dimensions(clust_depth, probe_data):\n",
    "    real_depths = []\n",
    "    \n",
    "    for depth_info in clust_depth:\n",
    "        depth, session_id = depth_info  # Unpacking depth and session ID from each tuple\n",
    "        # Get the probe start depth for this session from the probe data\n",
    "        session_probe_data = probe_data[probe_data['Recording Session'] == session_id]\n",
    "        if not session_probe_data.empty:\n",
    "            probe_start = session_probe_data['Probe_Start'].iloc[0]\n",
    "\n",
    "            # Convert the clust_depth value for this session\n",
    "            # Since clust_depth value is below the start of the probe, convert from µm to mm and adjust from the start\n",
    "            real_depth = round(probe_start - (depth / 1000), 3)\n",
    "            real_depths.append((real_depth, session_id))\n",
    "        else:\n",
    "            # If no corresponding probe data, use None for depth and keep session ID\n",
    "            real_depths.append((None, session_id))\n",
    "\n",
    "    return real_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_psth_data(data, laser_off_indices, laser_on_indices, axis=0):\n",
    "    \"\"\"\n",
    "    Calculate the mean for 'laserOn' and 'laserOff' conditions for each cell and normalize the 'laserOn' mean \n",
    "    to the range derived from the 'laserOff' mean.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: numpy array, the PSTH data with dimensions that can vary.\n",
    "    - laser_off_indices: numpy array or list, indices indicating the laser off condition.\n",
    "    - laser_on_indices: numpy array or list, indices indicating the laser on condition.\n",
    "    - axis: int, the axis along which the means are calculated and conditions are defined.\n",
    "    \n",
    "    Returns:\n",
    "    - norm_mean_off: numpy array, normalized mean data for the 'laserOff' condition.\n",
    "    - norm_mean_on: numpy array, normalized mean data for the 'laserOn' condition to the 'laserOff' range.\n",
    "    \"\"\"\n",
    "    # Calculate means across the specified axis for both conditions\n",
    "    mean_off = np.take(data, laser_off_indices, axis=axis).mean(axis=axis)\n",
    "    mean_on = np.take(data, laser_on_indices, axis=axis).mean(axis=axis)\n",
    "    \n",
    "    # Calculate normalization parameters based on the 'laserOff' mean\n",
    "    min_off = np.min(mean_off, axis=0, keepdims=True)\n",
    "    max_off = np.max(mean_off, axis=0, keepdims=True)\n",
    "    \n",
    "    # Normalize both 'laserOff' and 'laserOn' mean data to the 'laserOff' mean range\n",
    "    norm_mean_off = (mean_off - min_off) / np.where(max_off != min_off, max_off - min_off, 1)\n",
    "    norm_mean_on = (mean_on - min_off) / np.where(max_off != min_off, max_off - min_off, 1)\n",
    "    \n",
    "    return norm_mean_off, norm_mean_on\n",
    "\n",
    "\n",
    "# Define the modified function to handle NaN values\n",
    "def calculate_sem(data):\n",
    "    \"\"\"Calculate the Standard Error of the Mean (SEM) along the specified axis, ignoring NaNs.\"\"\"\n",
    "    return np.nanstd(data, axis=1) / np.sqrt(np.sum(~np.isnan(data), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_laserOff_TC(data1, data2):\n",
    "    norm_data1 = np.empty(data1.shape)\n",
    "    norm_data2 = np.empty(data2.shape)\n",
    "    \n",
    "    for cell in range(data1.shape[1]):\n",
    "        min_data1 = np.min(data1[:, cell])\n",
    "        max_data1 = np.max(data1[:, cell])\n",
    "        \n",
    "        # Normalize data1 to its own range\n",
    "        norm_data1[:, cell] = (data1[:, cell] - min_data1) / (max_data1 - min_data1)\n",
    "        \n",
    "        # Normalize data2 to the range of data1\n",
    "        norm_data2[:, cell] = (data2[:, cell] - min_data1) / (max_data1 - min_data1)\n",
    "    \n",
    "    return norm_data1, norm_data2\n",
    "\n",
    "def calculate_mTC(data, tones, freqs):\n",
    "    mTC = np.zeros((len(freqs), data.shape[1]))\n",
    "    for uniq in range(len(freqs)):\n",
    "        mTC[uniq, :] = data[tones == freqs[uniq], :].mean(axis=0)\n",
    "    return mTC\n",
    "\n",
    "def calculate_psthTC(PSTH, tonescond1, tonescond2, freqs, lasercond1, lasercond2):\n",
    "    num_uniq = len(freqs)\n",
    "    time_points = PSTH.shape[1]\n",
    "    num_cells = PSTH.shape[2]\n",
    "    psthTC1 = np.zeros((num_uniq, time_points, num_cells))\n",
    "    psthTC2 = np.zeros((num_uniq, time_points, num_cells))\n",
    "\n",
    "    for uniq in range(num_uniq):\n",
    "        toneTrial1 = PSTH[lasercond1, :, :][tonescond1 == freqs[uniq]]\n",
    "        toneTrial_2 = PSTH[lasercond2, :, :][tonescond2 == freqs[uniq]]\n",
    "        psthTC1[uniq, :, :] = toneTrial1.mean(axis=0)\n",
    "        psthTC2[uniq, :, :] = toneTrial_2.mean(axis=0)\n",
    "\n",
    "    return psthTC1, psthTC2\n",
    "\n",
    "def fit_and_predict(TC1, TC2):\n",
    "  \n",
    "    slope = np.zeros(TC1.shape[1])\n",
    "    intercept = np.zeros(TC1.shape[1])\n",
    "    y_preds = np.zeros_like(TC1)\n",
    "    \n",
    "    for cell in range(TC1.shape[1]):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        model = LinearRegression(fit_intercept=True)\n",
    "        modelfit = model.fit(TC1[:, cell].reshape((-1, 1)), TC2[:, cell])\n",
    "        slope[cell] = modelfit.coef_[0]  # Extract the first element \n",
    "        intercept[cell] = modelfit.intercept_\n",
    "        y_preds[:, cell] = modelfit.predict(TC1[:, cell].reshape((-1, 1)))\n",
    "    return slope, intercept, y_preds\n",
    "\n",
    "def calculate_sparseness(*conditions):\n",
    "   \n",
    "    def calc_sparseness(resp):\n",
    "        N = len(resp)\n",
    "        a = ((np.sum(resp)/N)**2) / np.sum((resp**2)/N)\n",
    "        s = (1-a) / (1 - (1/N))\n",
    "        return s\n",
    "    \n",
    "    results = []\n",
    "    for condition in conditions:\n",
    "        sparseness_values = [calc_sparseness(condition[:, cell]) for cell in range(condition.shape[1])]\n",
    "        results.append(sparseness_values)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_time_to_peak(peak_data_off, peak_data_on, edges_early_evoked_Ind, spontInd):\n",
    "    t2pOff, t2pOn = [], []\n",
    "    for cell in range(len(peak_data_on[0])):\n",
    "        bOff, _ = signal.find_peaks(peak_data_off[early_evoked_Ind, cell], height=(\n",
    "            np.mean(peak_data_off[spontInd, cell]) +\n",
    "            (np.std(peak_data_off[spontInd, cell]) * 3)))\n",
    "        bOn, _ = signal.find_peaks(peak_data_on[early_evoked_Ind, cell], height=(\n",
    "            np.mean(peak_data_on[spontInd, cell]) +\n",
    "            (np.std(peak_data_on[spontInd, cell]) * 3)))\n",
    "\n",
    "        if bOff.size > 0:\n",
    "            i_max_peak_Off = bOff[np.argmax(peak_data_off[early_evoked_Ind, cell][bOff])]\n",
    "            x_max_Off = edges[edges_early_evoked_Ind][i_max_peak_Off]\n",
    "            t2pOff.append(x_max_Off)\n",
    "        else:\n",
    "            t2pOff.append(np.nan)  # Handle case where no peak is found\n",
    "        \n",
    "        if bOn.size > 0:\n",
    "            i_max_peak_On = bOn[np.argmax(peak_data_on[early_evoked_Ind, cell][bOn])]\n",
    "            x_max_On = edges[edges_early_evoked_Ind][i_max_peak_On]\n",
    "            t2pOn.append(x_max_On)\n",
    "        else:\n",
    "            t2pOn.append(np.nan)  # Handle case where no peak is found\n",
    "\n",
    "    return t2pOff, t2pOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BF_and_uBF(off_responses, on_responses, freqs, side_freq):\n",
    "    # Nested function to process contextual responses\n",
    "    def process_contextual_responses(i, freqs_array, freqs, side_freq, off_responses, on_responses, off_context_resp, on_context_resp):\n",
    "        freq_index = np.argwhere(freqs_array[i] == freqs).flatten()[0]\n",
    "        nearby_indices = np.arange(freq_index - side_freq, freq_index + side_freq + 1).astype('float')\n",
    "        nearby_indices[np.logical_or(nearby_indices < 0, nearby_indices >= len(freqs))] = np.NaN\n",
    "\n",
    "        off_context_resp[:, i] = np.nan\n",
    "        valid = ~np.isnan(nearby_indices)\n",
    "        valid_indices = nearby_indices[valid].astype(int)\n",
    "        off_context_resp[valid, i] = off_responses[valid_indices, i]\n",
    "\n",
    "        on_context_resp[:, i] = np.nan\n",
    "        on_context_resp[valid, i] = on_responses[valid_indices, i]\n",
    "\n",
    "    # Initialization for best and un-best frequencies\n",
    "    best_freqs = np.empty(len(off_responses[0]))\n",
    "    max_responses = np.array([np.max(off_responses[:, cell]) for cell in range(len(off_responses[0]))]).squeeze()\n",
    "    off_context_resp_BF = np.empty([2 * side_freq + 1, len(off_responses[0])])\n",
    "    on_context_resp_BF = np.empty([2 * side_freq + 1, len(off_responses[0])])\n",
    "\n",
    "    uBF = np.empty(len(off_responses[0]))  # un-best frequencies\n",
    "    min_responses = np.array([np.min(off_responses[:, cell]) for cell in range(len(off_responses[0]))]).squeeze()\n",
    "    off_context_resp_uBF = np.empty([2 * side_freq + 1, len(off_responses[0])])\n",
    "    on_context_resp_uBF = np.empty([2 * side_freq + 1, len(off_responses[0])])\n",
    "\n",
    "    for cell in range(len(off_responses[0])):\n",
    "        # Process for best frequencies\n",
    "        max_resp_freqs = freqs[np.where(off_responses[:, cell] == np.max(off_responses[:, cell]))]\n",
    "        best_freqs[cell] = max_resp_freqs[0] if max_resp_freqs.size else max_resp_freqs\n",
    "        \n",
    "        # Process for un-best frequencies\n",
    "        min_resp_freqs = freqs[np.where(off_responses[:, cell] == np.min(off_responses[:, cell]))]\n",
    "        uBF[cell] = min_resp_freqs[0] if min_resp_freqs.size else min_resp_freqs\n",
    "\n",
    "    for i in range(len(off_responses[0])):\n",
    "        # Handling best frequencies\n",
    "        process_contextual_responses(i, best_freqs, freqs, side_freq, off_responses, on_responses, off_context_resp_BF, on_context_resp_BF)\n",
    "        \n",
    "        # Handling un-best frequencies\n",
    "        process_contextual_responses(i, uBF, freqs, side_freq, off_responses, on_responses, off_context_resp_uBF, on_context_resp_uBF)\n",
    "\n",
    "    return best_freqs, max_responses, off_context_resp_BF, on_context_resp_BF, uBF, min_responses, off_context_resp_uBF, on_context_resp_uBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure_directory(cellType, Virus, data_paper, stim):\n",
    "    fig_path = os.path.join(dataLoc, f'{cellType}_Recordings/{Virus}/{data_paper}')\n",
    "    date = datetime.now().strftime('%d%m%Y')\n",
    "    date_time = datetime.now().strftime('%d%m%Y%I%M%p')\n",
    "    \n",
    "    fig_folder = 'Figures_{}'.format(cellType)\n",
    "    fig_folder_name = f'Figures_AllCells_{date}'\n",
    "    fig_folder_name_detailed = f'Figures_AllCells_{date_time}_{stim}'\n",
    "    \n",
    "    fig_dir = os.path.join(fig_path, fig_folder, fig_folder_name)\n",
    "    fig_dir_time = os.path.join(fig_path, fig_folder, fig_folder_name, fig_folder_name_detailed)\n",
    "\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "    if not os.path.exists(fig_dir_time):\n",
    "        os.makedirs(fig_dir_time)\n",
    "        \n",
    "    return fig_dir, fig_dir_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cells_psth(full_or_mean_psth_off, full_or_mean_psth_on, time_points, \n",
    "                    start_of_laser, start_of_stimulus, duration_of_stimulus, \n",
    "                    normalized_psth_off=None, normalized_psth_on=None, \n",
    "                    laser_only_psth=None, laser_only_duration=None, show_plots=True):\n",
    "    \n",
    "    if full_or_mean_psth_off.ndim == 3:\n",
    "        mean_off_responses = full_or_mean_psth_off.mean(axis=0)\n",
    "        mean_on_responses = full_or_mean_psth_on.mean(axis=0)\n",
    "    else:\n",
    "        mean_off_responses = full_or_mean_psth_off\n",
    "        mean_on_responses = full_or_mean_psth_on\n",
    "\n",
    "    if laser_only_psth is not None and laser_only_psth.ndim == 3:\n",
    "        mean_laser_only_responses = laser_only_psth.mean(axis=0)\n",
    "    elif laser_only_psth is not None:\n",
    "        mean_laser_only_responses = laser_only_psth\n",
    "\n",
    "    cell_count = mean_off_responses.shape[1]\n",
    "    include_normalized_plots = normalized_psth_off is not None and normalized_psth_on is not None\n",
    "\n",
    "    if show_plots:\n",
    "        plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "        for cell_idx in range(cell_count):\n",
    "            subplot_count = 1 + (1 if include_normalized_plots or laser_only_psth is not None else 0)\n",
    "            fig, ax = plt.subplots(1, subplot_count, figsize=(2.5 * subplot_count, 2))\n",
    "            if subplot_count == 1:\n",
    "                ax = np.array([ax])\n",
    "\n",
    "            ax[0].plot(time_points, mean_off_responses[:, cell_idx], 'k')\n",
    "            ax[0].plot(time_points, mean_on_responses[:, cell_idx])\n",
    "            ax[0].axvline(x=start_of_laser, ls='--', c='c')\n",
    "            ax[0].axvline(x=start_of_stimulus, ls='--', c='k')\n",
    "            ax[0].axvline(x=duration_of_stimulus, ls='--', c='k')\n",
    "            ax[0].set(xlabel='Time (s)', ylabel='FR (Hz)', title=f'PSTH for Cell ID = {cell_idx}')\n",
    "            ax[0].legend(['Laser Off', 'Laser On'])\n",
    "\n",
    "            next_ax_idx = 1\n",
    "\n",
    "            if include_normalized_plots:\n",
    "                ax[next_ax_idx].plot(time_points, normalized_psth_off[:, cell_idx], 'k')\n",
    "                ax[next_ax_idx].plot(time_points, normalized_psth_on[:, cell_idx])\n",
    "                ax[next_ax_idx].axvline(x=start_of_laser, ls='--', c='c')\n",
    "                ax[next_ax_idx].axvline(x=start_of_stimulus, ls='--', c='k')\n",
    "                ax[next_ax_idx].axvline(x=duration_of_stimulus, ls='--', c='k')\n",
    "                ax[next_ax_idx].set(xlabel='Time (s)', ylabel='Normalized FR', title=f'Normalized PSTH for Cell ID = {cell_idx}')\n",
    "                ax[next_ax_idx].legend(['Laser Off', 'Laser On'])\n",
    "                next_ax_idx += 1\n",
    "\n",
    "            if laser_only_psth is not None:\n",
    "                ax[next_ax_idx].plot(time_points, mean_laser_only_responses[:, cell_idx], 'k')\n",
    "                ax[next_ax_idx].axvline(x=start_of_laser, ls='--', c='k')\n",
    "                ax[next_ax_idx].axvline(x=laser_only_duration, ls='--', c='k')\n",
    "                ax[next_ax_idx].set(xlabel='Time (s)', ylabel='FR (Hz)', title=f'Laser Only PSTH for Cell ID = {cell_idx}')\n",
    "                ax[next_ax_idx].legend(['Laser Only'])\n",
    "\n",
    "            fig.align_labels()\n",
    "\n",
    "    # Regardless of plotting, always return the mean off and on responses.\n",
    "    return mean_off_responses, mean_on_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_TC(freqs, mTCcond1, mTCcond2, ax=None, title=\"\"):\n",
    "    # Check if the ax parameter is None. If so, create a new figure and axes.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(2, 1.5)\n",
    "        created_fig = True\n",
    "    else:\n",
    "        created_fig = False  # To know whether to show the plot and return a figure\n",
    "        \n",
    "    ax.plot(freqs, mTCcond1.mean(axis=1), color='black')  # Assuming _new_black was a color\n",
    "    ax.plot(freqs, mTCcond2.mean(axis=1), color='CornflowerBlue')\n",
    "    ax.set_ylabel('FR (Hz)')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_box_aspect(1)\n",
    "    \n",
    "    # Show the plot if this function created the figure; otherwise, it's the caller's responsibility.\n",
    "    if created_fig:\n",
    "        plt.show()\n",
    "        return fig\n",
    "    else:\n",
    "        return ax  # Return the modified ax if it was provided by the caller\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_mean_tuning_curves(mTCOff_V, mTCOn_V, freqs):\n",
    "    \"\"\"\n",
    "    Plots mean tuning curves for given firing rates and frequencies.\n",
    "\n",
    "    Parameters:\n",
    "    - mTCOff: 2D array of mean tuning curves with laser off (conditions x cells).\n",
    "    - mTCOn: 2D array of mean tuning curves with laser on (conditions x cells).\n",
    "    - freqs: 1D array of frequencies.\n",
    "    \"\"\"\n",
    "    for cell in range(mTCOff_V.shape[1]):\n",
    "        fig, ax = plt.subplots(figsize=(5, 3))\n",
    "        ax.plot(freqs, mTCOff_V[:, cell], 'k')\n",
    "        ax.plot(freqs, mTCOn_V[:, cell], 'CornflowerBlue')\n",
    "        ax.set_ylabel('FR (Hz)')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_title('tc= %i' % cell)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_centered_individual_tuning_curves(cFR_V, cFR_On_V, octaves_V, cell_range=None):\n",
    "    \"\"\"\n",
    "    Plots tuning curves for given firing rates and octaves.\n",
    "\n",
    "    Parameters:\n",
    "    - cFR: 2D array of firing rates with laser off (conditions x cells).\n",
    "    - cFR_On: 2D array of firing rates with laser on (conditions x cells).\n",
    "    - octaves: 1D array of octaves.\n",
    "    - cell_range: tuple of (start, end) to specify range of cells to plot. If None, all cells are plotted.\n",
    "    \"\"\"\n",
    "    if cell_range is None:\n",
    "        cell_range = (0, cFR_V.shape[1])\n",
    "\n",
    "    for cell in range(*cell_range):\n",
    "        fig, ax = plt.subplots(figsize=(5, 3))\n",
    "        ax.errorbar(octaves_V, cFR_V[:, cell], ecolor='k', linestyle='-', color='k', \n",
    "                    markerfacecolor='k', marker='o', markersize=8, capsize=5)\n",
    "\n",
    "        ax.errorbar(octaves_V, cFR_On_V[:, cell], ecolor='CornflowerBlue', linestyle='-', \n",
    "                    color='CornflowerBlue', markerfacecolor='CornflowerBlue', \n",
    "                    marker='o', markersize=8, capsize=5)\n",
    "\n",
    "        ax.set_xlim(np.round(octaves_V[0] - 0.025, 3), np.round(octaves[-1] + 0.025, 3))\n",
    "        ax.set_xticks(np.round(octaves_V, 2))\n",
    "        ax.xaxis.set_major_formatter(FormatStrFormatter('%0.2g'))\n",
    "        ax.set_title('Norm PSTH for Cell ID = %i' % cell)\n",
    "        ax.set_ylabel('FR (Hz)', labelpad=10)\n",
    "        ax.set_xlabel('Octaves from Best Frequency', labelpad=10)\n",
    "        ax.legend(['Laser Off', 'Laser On'], bbox_to_anchor=(1, 1))\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_responses(spike_sort_indices, rasters, freq, title_prefix=\"Cell\"):\n",
    "    \"\"\"\n",
    "    Plots raster plots for responses to different frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "    - spike_sort_indices: List of arrays, each containing spike sorting indices for responses.\n",
    "    - rasters: List of arrays, each containing raster data for responses.\n",
    "    - freq: Array of unique frequencies.\n",
    "    - title_prefix: String to prefix the title with, followed by the cell ID.\n",
    "    \"\"\"\n",
    "    cmap = cmr.get_sub_cmap(\"cmr.tropical\", 0.1, 1, N=len(freq))\n",
    "\n",
    "    for l, spike_indices in enumerate(spike_sort_indices):\n",
    "        cInd = np.ceil(spike_indices / 20) * 20\n",
    "        midpoint = np.max(cInd / 2)\n",
    "        sortind_c_off = spike_indices <= midpoint\n",
    "        sortind_c_on = spike_indices > midpoint\n",
    "\n",
    "        if max(spike_indices[sortind_c_off], default=-1) >= len(rasters[l]) or max(spike_indices[sortind_c_on], default=-1) >= len(rasters[l]):\n",
    "            print(f\"Index out of bounds for cell {l}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        rastoff = np.asarray(rasters[l])[sortind_c_off]\n",
    "        raston = np.asarray(rasters[l])[sortind_c_on]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 3), constrained_layout=True)\n",
    "        cax = ax.scatter(rastoff, sortind_c_off, s=0.5, c=sortind_c_off, cmap=cmap, marker='|', linewidth=0.5)\n",
    "        cax2 = ax.scatter(raston, sortind_c_on, s=0.5, c=sortind_c_on, cmap=cmap, marker='|', linewidth=0.5)\n",
    "\n",
    "        cbar = fig.colorbar(cax)\n",
    "        cbar.ax.yaxis.set_major_locator(ticker.LinearLocator(numticks=len(freq)))\n",
    "        cbar.ax.set_yticklabels(np.around(freq / 1000, decimals=1), fontsize=10)\n",
    "        cbar.set_label('Frequency (kHz)', fontsize='small')\n",
    "\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Trials')\n",
    "        ax.set_title(f'{title_prefix} for Cell ID = {l}')\n",
    "        ax.tick_params(axis='both')\n",
    "        ax.locator_params(nbins=5, axis='y')\n",
    "        ax.locator_params(nbins=8, axis='x')\n",
    "        ax.set_ylim(top=max(spike_indices) + 1)\n",
    "        ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Data Analysis Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the base directory for where the data and stimulus files are stored on your computer.\n",
    "excel_path = '/Users/solymarrolon/Data/probe_depth_per_recording.xlsx' # Load probe data\n",
    "dataLoc = '/Users/solymarrolon/Data/OpenEphys/MGB_Recordings/' # Base directory for data files\n",
    "stim_loc = '/Users/solymarrolon/Data/Stimuli/02232022/'  # Base directory for stimulus files\n",
    "\n",
    "\n",
    "# Specify the main tuning curve stimulus file name and laser only stimulus file name.\n",
    "main_stim_file = \"TuningCurve_50ms_Laser_50ms_Frequencies3_80Hz_02232022_stimInfo\"  # Main stimulus file\n",
    "laser_stim_file = \"LaserStim_Optotag_50ms_400ISI_5Reps_stimInfo\" # Main laser stimulus file\n",
    "\n",
    "\n",
    "# Uncomment the line corresponding to the dataset you are working with.\n",
    "\n",
    "date = '04192024'\n",
    "date_Laser = '04192024'\n",
    "\n",
    "# date = '05012024'  # folder for PV Controls\n",
    "# date_Laser = '05012024'  # folder for SOM Controls\n",
    "\n",
    "\n",
    "# Define the cell type and viral vector used in the experiment.\n",
    "\n",
    "cellType = 'SOM'\n",
    "# cellType = 'PV'\n",
    "\n",
    "\n",
    "Virus = 'stGtACR1'\n",
    "# Virus = 'Controls'\n",
    "\n",
    "\n",
    "# Use absolute paths for data loading to avoid changing directories within the script.\n",
    "\n",
    "# Construct paths for saving or accessing processed spike data related to this analysis.\n",
    "data_paper = 'Data_Paper'\n",
    "\n",
    "# Construct data folder paths\n",
    "dataFolder = f'{cellType}_Recordings/{Virus}/{data_paper}/PSTH/PSTH_{main_stim_file.replace(\".mat\", \"\")}_{date}'\n",
    "dataFolder_Laser = f'{cellType}_Recordings/{Virus}/{data_paper}/PSTH/PSTH_{laser_stim_file.replace(\".mat\", \"\")}_{date_Laser}'\n",
    "\n",
    "data_path = os.path.join(dataLoc, dataFolder)\n",
    "data_path_laser = os.path.join(dataLoc, dataFolder_Laser)\n",
    "\n",
    "\n",
    "# Define repetition counts for the stimulus presented.\n",
    "nreps = 2 # Number of repetitions for the tuning curve stimulus.\n",
    "nreps_laser = 10 # Number of repetitions for the laser-only stimulus.\n",
    "\n",
    "laserStart = 0\n",
    "tStart = 0\n",
    "\n",
    "# Use the load_experiment_data function to load and process experimental data:\n",
    "# This will output the PSTH, cluster depth, raster data, trials, spike sorting indices, and laser-specific PSTH.\n",
    "\n",
    "allPSTH, allPSTH_S, Clust_Depth, Rasters, Trials, SpikeSortInd, allPSTH_Laser, allPSTH_Laser_S, trialOrder, ITI, ITI_laser, laserDur, laserOnlyDur, tDur, binSize, edges, time, session_guide, session_guide_laser = load_experiment_data(data_path, main_stim_file, data_path_laser, laser_stim_file, stim_loc, nreps, nreps_laser)\n",
    "\n",
    "\n",
    "# Summarize_data function to get number of cells (FullPST (trials, time, neurons)):\n",
    "summarize_data(Rasters, SpikeSortInd, Clust_Depth, allPSTH, allPSTH_S, allPSTH_Laser, allPSTH_Laser_S)\n",
    "\n",
    "\n",
    "probe_data = load_probe_data(excel_path, cellType, Virus)\n",
    "\n",
    "# Create figure directory using the create_figure_directory function:\n",
    "fig_dir, fig_dir_time = create_figure_directory(cellType, Virus, data_paper, main_stim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start PSTH analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique frequencies and the stimulus index \n",
    "uniq_Freq, stim_Ind = np.unique(trialOrder[:, 0], return_inverse=True)\n",
    "laserCond, laser_Ind = np.unique(trialOrder[:, 1], return_inverse=True)\n",
    "\n",
    "# Directly obtain laserOn and laserOff trial indices based on laser_Ind and the trialOrder array.\n",
    "laserOn = np.flatnonzero(trialOrder[:, 1] == 1)\n",
    "laserOff = np.flatnonzero(trialOrder[:, 1] == 0)\n",
    "\n",
    "# Define the time indeces:\n",
    "spontInd = np.where((time <= tStart))[0].squeeze()\n",
    "early_evoked_Ind = np.where((time >= tStart) & (time <= 0.025))[0].squeeze()\n",
    "late_evoked_Ind = np.where((time > 0.025) & (time <= tDur))[0].squeeze()\n",
    "offsetInd = np.where((time > tDur) & (time <= 0.100))[0].squeeze()\n",
    "late_offsetInd = np.where((time > 0.100) & (time <= time[-1]))[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the probe\n",
    "tip_to_last_channel = 0.075  # 75µm in mm\n",
    "channel_span = 0.775  # 775µm in mm\n",
    "\n",
    "\n",
    "# Convert depth from micrometers to millimeters and adjust\n",
    "probe_data['Total_Probe_End'] = (probe_data['Depth'] / 1000)\n",
    "probe_data['Probe_End'] = (probe_data['Depth'] / 1000) - tip_to_last_channel\n",
    "probe_data['Probe_Start'] = probe_data['Total_Probe_End'] - (tip_to_last_channel + channel_span)\n",
    "\n",
    "  \n",
    "real_cluster_depths = map_cluster_depths_to_real_dimensions(Clust_Depth, probe_data)\n",
    "real_cluster_depths = np.array(real_cluster_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort psth per depth of the probe:\n",
    "# Assuming real_cluster_depths is a list of tuples (depth, session_id)\n",
    "depths_only = [depth if depth is not None else float('inf') for depth, session in real_cluster_depths]\n",
    "sorted_indices = np.argsort(depths_only)\n",
    "\n",
    "# Example arrays allPSTH, allPSTH_S, etc. need to be defined appropriately\n",
    "sortedFullPSTH_unsmoothed = allPSTH[:, :, sorted_indices]\n",
    "sortedFullPSTH = allPSTH_S[:, :, sorted_indices]\n",
    "sortedFullPSTH_Laser = allPSTH_Laser_S[:, :, sorted_indices]\n",
    "\n",
    "depth = [real_cluster_depths[idx] for idx in sorted_indices]  # This retains the tuple structure\n",
    "Rasters_sort = Rasters[sorted_indices]  # Assuming Rasters has a compatible shape\n",
    "Trials_sort = Trials[sorted_indices]\n",
    "SpikeSortInd_sort = SpikeSortInd[sorted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using the normalize_psth_data function\n",
    "norm_PSTH_OFF, norm_PSTH_On = normalize_psth_data(sortedFullPSTH, laserOff, laserOn, axis=0) \n",
    "\n",
    "# Normalize data for laser-only condition\n",
    "norm_PSTH_LaserOnly = np.empty_like(sortedFullPSTH_Laser.mean(axis=0))\n",
    "\n",
    "# Loop through each cell to normalize the data individually\n",
    "for cell in range(sortedFullPSTH_Laser.shape[2]):\n",
    "    # Calculate the mean for the current cell across all trials\n",
    "    mean_cell = sortedFullPSTH_Laser[:, :, cell].mean(axis=0)\n",
    "    \n",
    "    # Compute the minimum and maximum values for normalization\n",
    "    min_val, max_val = mean_cell.min(), mean_cell.max()\n",
    "    \n",
    "    # Normalize the mean PSTH data for the current cell\n",
    "    # Handle division by zero if max_val equals min_val\n",
    "    norm_PSTH_LaserOnly[:, cell] = (mean_cell - min_val) / (max_val - min_val) if max_val != min_val else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the mean PSTH for both LaserOn and LaserOff conditions for each cell. Optional: plot individual PSTH's by changing show_plots = TRUE.\n",
    "meanLaserOff, meanLaserOn = plot_cells_psth(\n",
    "    sortedFullPSTH[laserOff, :, :], \n",
    "    sortedFullPSTH[laserOn, :, :], \n",
    "    time, \n",
    "    laserStart, \n",
    "    tStart, \n",
    "    tDur, \n",
    "    norm_PSTH_OFF, \n",
    "    norm_PSTH_On, show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize lists\n",
    "peakVal = []\n",
    "laser_p_evokedEarly = []\n",
    "significant = []\n",
    "\n",
    "# Define non-significant value\n",
    "non_significant_value = np.nan\n",
    "\n",
    "for cell in range(meanLaserOff.shape[1]):\n",
    "    # Calculate peakVal based on your criteria\n",
    "    peak_height_threshold = np.mean(meanLaserOff[spontInd, cell]) + np.std(meanLaserOff[spontInd, cell]) * 3\n",
    "    peaks, properties = signal.find_peaks(meanLaserOff[early_evoked_Ind, cell], height=peak_height_threshold)\n",
    "    if len(peaks) > 0 and np.max(properties[\"peak_heights\"]) > 0:\n",
    "        peakVal.append(1)  # Indicate significant peak found\n",
    "    else:\n",
    "        peakVal.append(0)  # Indicate no significant peak found\n",
    "\n",
    "    # Calculate laser_p_evokedEarly only for cells with a peakVal > 0\n",
    "    if peakVal[-1] > 0:\n",
    "        meanOff = np.mean(meanLaserOff[early_evoked_Ind, cell], axis = 0)\n",
    "        meanOn = np.mean(meanLaserOn[early_evoked_Ind, cell], axis = 0)\n",
    "\n",
    "        if meanOn == 0 or meanOff == 0:\n",
    "            LpEE = non_significant_value\n",
    "            significant.append(0)  # Non-significant result due to zero means\n",
    "        else:\n",
    "            try:\n",
    "                _, LpEE = stats.wilcoxon(meanLaserOff[early_evoked_Ind, cell], meanLaserOn[early_evoked_Ind, cell])\n",
    "                laser_p_evokedEarly.append(LpEE)\n",
    "                significant.append(1 if LpEE < 0.05 else 0)  # Assuming 0.05 as the significance level\n",
    "            except ValueError:\n",
    "                laser_p_evokedEarly.append(non_significant_value)\n",
    "                significant.append(0)  # Error in computation leads to non-significant result\n",
    "    else:\n",
    "        laser_p_evokedEarly.append(non_significant_value)\n",
    "        significant.append(0)  # No peak, so non-significant by definition\n",
    "\n",
    "# Set the specific index for peakVal=1 and significant=0\n",
    "toneIndex = np.squeeze(np.where((np.asarray(peakVal) == 1) & (np.asarray(significant) == 0)))\n",
    "\n",
    "# Set the significance index\n",
    "sigtoneindex = np.squeeze(np.where((np.asarray(peakVal) == 1) & (np.asarray(significant) == 1)))\n",
    "\n",
    "\n",
    "print(f\"Number of non-significant cells with peaks: {len(toneIndex)}\")\n",
    "\n",
    "# Select signiticant units to *tone* only:\n",
    "toneOnlyRespPSTH = sortedFullPSTH[:,:,toneIndex]\n",
    "toneOnlyRespPSTH_Laser = sortedFullPSTH[:,:,toneIndex]\n",
    "\n",
    "meanLaserOff_toneonly_masked = toneOnlyRespPSTH[laserOff,:,:].mean(axis=0)\n",
    "meanLaserOn_toneonly_masked = toneOnlyRespPSTH[laserOn,:,:].mean(axis=0)\n",
    "\n",
    "norm_PSTH_OFF_toneonly_masked = norm_PSTH_OFF[:,toneIndex]\n",
    "norm_PSTH_On_toneonly_masked = norm_PSTH_On[:,toneIndex]\n",
    "\n",
    "PSTH_Laser_norm_toneonly_masked = norm_PSTH_LaserOnly[:,toneIndex]\n",
    "\n",
    "Clust_Depth_toneRespOnly = np.array([depth[i] for i in toneIndex])\n",
    "Rasters_toneRespOnly = Rasters_sort[toneIndex]\n",
    "Trials_toneRespOnly = Trials_sort[toneIndex]\n",
    "SpikeSortI_toneRespOnly = SpikeSortInd_sort[toneIndex]\n",
    "\n",
    "\n",
    "\n",
    "# Select signiticant units to *tone and laser*: \n",
    "toneRespPSTH = sortedFullPSTH[:,:,sigtoneindex]\n",
    "toneRespPSTH_Laser = sortedFullPSTH_Laser[:,:,sigtoneindex]\n",
    "\n",
    "meanLaserOff_masked = toneRespPSTH[laserOff,:,:].mean(axis=0)\n",
    "meanLaserOn_masked = toneRespPSTH[laserOn,:,:].mean(axis=0)\n",
    "\n",
    "norm_PSTH_OFF_masked = norm_PSTH_OFF[:,sigtoneindex]\n",
    "norm_PSTH_On_masked = norm_PSTH_On[:,sigtoneindex]\n",
    "\n",
    "PSTH_Laser_norm_masked = norm_PSTH_LaserOnly[:,sigtoneindex]\n",
    "\n",
    "Clust_Depth_toneResp = np.array([depth[i] for i in sigtoneindex])\n",
    "Rasters_toneResp = Rasters_sort[sigtoneindex]\n",
    "Trials_toneResp = Trials_sort[sigtoneindex]\n",
    "SpikeSortI_toneResp = SpikeSortInd_sort[sigtoneindex]\n",
    "\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Shapes after filtering for tone & laser responsive units:\")\n",
    "print(\"Tone responsive PSTH shape:\", np.shape(toneRespPSTH))\n",
    "print(\"Tone responsive PSTH Laser shape:\",np.shape(toneRespPSTH_Laser))\n",
    "print(\"Cluster Depth tone-responsive shape:\",Clust_Depth_toneResp.shape)\n",
    "print(\"Rasters tone-responsive shape:\", Rasters_toneResp.shape)\n",
    "print(\"Trials tone-responsive shape:\",Trials_toneResp.shape)\n",
    "print(\"Spike Sort Index tone-responsive shape:\",SpikeSortI_toneResp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select the appropriate traces for spontaneous activity, evoked activity & offset\n",
    "spontTrace = toneRespPSTH[:,spontInd,:] \n",
    "evokedTrace = toneRespPSTH[:,early_evoked_Ind,:]\n",
    "late_evokedTrace = toneRespPSTH[:,late_evoked_Ind,:]\n",
    "offsetTrace = toneRespPSTH[:,offsetInd,:]\n",
    "\n",
    "\n",
    "spontTrace_normOff = norm_PSTH_OFF_masked[spontInd,:] \n",
    "evokedTrace_norm_normOff = norm_PSTH_OFF_masked[early_evoked_Ind,:]\n",
    "late_evokedTrace_norm_normOff = norm_PSTH_OFF_masked[late_evoked_Ind,:]\n",
    "offsetTrace_norm_normOff = norm_PSTH_OFF_masked[offsetInd,:]\n",
    "\n",
    "spontTrace_normOn = norm_PSTH_On_masked[spontInd,:] \n",
    "evokedTrace_norm_normOn = norm_PSTH_On_masked[early_evoked_Ind,:]\n",
    "late_evokedTrace_norm_normOn = norm_PSTH_On_masked[late_evoked_Ind,:]\n",
    "offsetTrace_norm_normOn = norm_PSTH_On_masked[offsetInd,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the results of the difference in mean firing rate laser on - laser off:\n",
    "diff_resp_EarlyOn = []\n",
    "diff_resp_norm_EarlyOn = []\n",
    "\n",
    "for cell in range(len(toneRespPSTH[0][0])):\n",
    "    # Calculate the difference between LaserOn and LaserOff\n",
    "    diff = meanLaserOn_masked[early_evoked_Ind, cell].mean(axis=0) - meanLaserOff_masked[early_evoked_Ind, cell].mean(axis=0)\n",
    "    diff_resp_EarlyOn.append(diff)\n",
    "\n",
    "    # Calculate the normalized difference\n",
    "    diff_norm = norm_PSTH_On_masked[early_evoked_Ind, cell].mean(axis=0) - norm_PSTH_OFF_masked[early_evoked_Ind, cell].mean(axis=0)\n",
    "    diff_resp_norm_EarlyOn.append(diff_norm)\n",
    "\n",
    "# Convert list to NumPy array for easier processing\n",
    "diff_resp_EarlyOn_array = np.array(diff_resp_EarlyOn)\n",
    "diff_resp_norm_EarlyOn_array = np.array(diff_resp_norm_EarlyOn)\n",
    "\n",
    "# Establish facilitation or suppression indices:\n",
    "facilitated_Ind = np.where(diff_resp_EarlyOn_array > 0)[0]\n",
    "suppressed_Ind = np.where(diff_resp_EarlyOn_array < 0)[0]\n",
    "\n",
    "# Compute differences in firing rated durng laserOn - laserOff for sorted facilitated and suppressed data\n",
    "diff_Sorted_facil = diff_resp_EarlyOn_array[facilitated_Ind]\n",
    "\n",
    "diff_Sorted_supp = diff_resp_EarlyOn_array[suppressed_Ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Index firing rates for facilitated and suppressed cells:\n",
    "facilitated_cells_Off = meanLaserOff_masked[:,facilitated_Ind]\n",
    "facilitated_cells_On = meanLaserOn_masked[:,facilitated_Ind]\n",
    "\n",
    "suppressed_cells_Off = meanLaserOff_masked[:,suppressed_Ind]\n",
    "suppressed_cells_On = meanLaserOn_masked[:,suppressed_Ind]\n",
    "\n",
    "facilitated_cells_Off_norm = norm_PSTH_OFF_masked[:,facilitated_Ind]\n",
    "facilitated_cells_On_norm = norm_PSTH_On_masked[:,facilitated_Ind]\n",
    "\n",
    "suppressed_cells_Off_norm = norm_PSTH_OFF_masked[:,suppressed_Ind]\n",
    "suppressed_cells_On_norm = norm_PSTH_On_masked[:,suppressed_Ind]\n",
    "\n",
    "mean_responses_facil_laser_only = toneRespPSTH_Laser[:, :, facilitated_Ind].mean(axis=0)  # Mean across neurons\n",
    "mean_responses_supp_laser_only = toneRespPSTH_Laser[:, :, suppressed_Ind].mean(axis=0)  # Mean across neurons\n",
    "\n",
    "\n",
    "# Index rasters, trials, and sorted indeces for facilitated and suppressed cells:\n",
    "Facil_Rasters_toneResp = Rasters_toneResp[facilitated_Ind]\n",
    "Facil_Trials_toneResp = Trials_toneResp[facilitated_Ind]\n",
    "Facil_SpikeSortI_toneResp = SpikeSortI_toneResp[facilitated_Ind]\n",
    "\n",
    "Supp_Rasters_toneResp = Rasters_toneResp[suppressed_Ind]\n",
    "Supp_Trials_toneResp = Trials_toneResp[suppressed_Ind]\n",
    "Supp_SpikeSortI_toneResp = SpikeSortI_toneResp[suppressed_Ind]\n",
    "\n",
    "\n",
    "# Convert the depth component of each tuple in facilitated_depths to float\n",
    "facilitated_depths = Clust_Depth_toneResp[facilitated_Ind]\n",
    "facilitated_depths = [(float(depth), session) if isinstance(depth, str) else (depth, session) for depth, session in facilitated_depths]\n",
    "\n",
    "# Convert the depth component of each tuple in suppressed_depths to float\n",
    "suppressed_depths = Clust_Depth_toneResp[suppressed_Ind]\n",
    "suppressed_depths = [(float(depth), session) if isinstance(depth, str) else (depth, session) for depth, session in suppressed_depths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_numeric = np.array([float(x[0]) for x in Clust_Depth_toneResp])\n",
    "depths_numeric_facil = np.array([float(x[0]) for x in facilitated_depths])\n",
    "depths_numeric_supp = np.array([float(x[0]) for x in suppressed_depths])\n",
    "\n",
    "# Bin the data per depth of the probe\n",
    "bin_size = .100  # Bin size in µm\n",
    "bins_depth = np.arange(np.min(depths_numeric), np.max(depths_numeric) + bin_size, bin_size)\n",
    "bin_centers = (bins_depth[:-1] + bins_depth[1:]) / 2  # Calculate bin centers for plotting\n",
    "\n",
    "\n",
    "# Digitize your depth data for each category\n",
    "bin_indices_facil = np.digitize(depths_numeric_facil, bins_depth)\n",
    "bin_indices_supp = np.digitize(depths_numeric_supp, bins_depth)\n",
    "\n",
    "bin_indices_facil = bin_indices_facil.astype(int)\n",
    "bin_indices_supp = bin_indices_supp.astype(int)\n",
    "\n",
    "# Convert to array for compatibility\n",
    "diff_Sorted_facil_norm = np.asarray(diff_Sorted_facil)\n",
    "diff_Sorted_supp_norm = np.asarray(diff_Sorted_supp)\n",
    "\n",
    "# Adjusted to handle empty slices\n",
    "facil_agg = np.array([np.mean(diff_Sorted_facil_norm[bin_indices_facil == i]) if np.any(bin_indices_facil == i) else np.nan for i in range(1, len(bins_depth))])\n",
    "supp_agg = np.array([np.mean(diff_Sorted_supp_norm[bin_indices_supp == i]) if np.any(bin_indices_supp == i) else np.nan for i in range(1, len(bins_depth))])\n",
    "\n",
    "# For sum, you might want to return 0 instead of np.nan when the slice is empty\n",
    "facil_sum = np.array([np.sum(diff_Sorted_facil_norm[bin_indices_facil == i]) if np.any(bin_indices_facil == i) else 0 for i in range(1, len(bins_depth))])\n",
    "supp_sum = np.array([np.sum(diff_Sorted_supp_norm[bin_indices_supp == i]) if np.any(bin_indices_supp == i) else 0 for i in range(1, len(bins_depth))])\n",
    "\n",
    "# Count occurrences for each bin for facilitated and suppressed conditions\n",
    "facil_counts = np.bincount(bin_indices_facil - 1, minlength=len(bins_depth)-1)\n",
    "supp_counts = np.bincount(bin_indices_supp - 1, minlength=len(bins_depth)-1)\n",
    "\n",
    "# Combine all depths to define the range of bins\n",
    "depth_all = np.concatenate([facilitated_depths, suppressed_depths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonesOn = uniq_Freq[stim_Ind[laserOn]]\n",
    "tonesOff = uniq_Freq[stim_Ind[laserOff]]\n",
    "\n",
    "\n",
    "\n",
    "evOff = evokedTrace[laserOff,:,:].mean(axis=1)\n",
    "evOn = evokedTrace[laserOn,:,:].mean(axis=1)\n",
    "\n",
    "norm_evOff, norm_evOn = normalize_to_laserOff_TC(evOff, evOn)\n",
    "\n",
    "mTCOff = calculate_mTC(evOff, tonesOff, uniq_Freq)\n",
    "mTCOn = calculate_mTC(evOn, tonesOn, uniq_Freq)\n",
    "\n",
    "mTCOff_norm = calculate_mTC(norm_evOff, tonesOff, uniq_Freq)\n",
    "mTCOn_norm = calculate_mTC(norm_evOn, tonesOn, uniq_Freq)\n",
    "\n",
    "slopes, intercepts, y_pred = fit_and_predict(mTCOff_norm, mTCOn_norm)\n",
    "\n",
    "\n",
    "# Example usage for the initial evokedTrace\n",
    "Late_evOff = late_evokedTrace[laserOff,:,:].mean(axis=1)\n",
    "Late_evOn = late_evokedTrace[laserOn,:,:].mean(axis=1)\n",
    "\n",
    "Late_norm_evOff, Late_norm_evOn = normalize_to_laserOff_TC(evOff, evOn)\n",
    "\n",
    "Late_mTCOff = calculate_mTC(Late_evOff, tonesOff, uniq_Freq)\n",
    "Late_mTCOn = calculate_mTC(Late_evOn, tonesOn, uniq_Freq)\n",
    "\n",
    "Late_mTCOff_norm = calculate_mTC(Late_norm_evOff, tonesOff, uniq_Freq)\n",
    "Late_mTCOn_norm = calculate_mTC(Late_norm_evOn, tonesOn, uniq_Freq)\n",
    "\n",
    "Late_slopes, Late_intercepts, Late_y_pred = fit_and_predict(Late_mTCOff_norm, Late_mTCOn_norm)\n",
    "\n",
    "\n",
    "# Calculate psthTC for both laser off and on conditions\n",
    "psthTC, psthTC_On = calculate_psthTC(toneRespPSTH, tonesOff, tonesOn, uniq_Freq, laserOff, laserOn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evOff_facil = evOff[:,facilitated_Ind]\n",
    "evOn_facil = evOn[:,facilitated_Ind]\n",
    "\n",
    "Late_evOff_facil = Late_evOff[:,facilitated_Ind]\n",
    "Late_evOn_facil = Late_evOn[:,facilitated_Ind]\n",
    "\n",
    "evOff_supp = evOff[:,suppressed_Ind]\n",
    "evOn_supp = evOn[:,suppressed_Ind]\n",
    "\n",
    "Late_evOff_supp = Late_evOff[:,suppressed_Ind]\n",
    "Late_evOn_supp = Late_evOn[:,suppressed_Ind]\n",
    "\n",
    "mTCOff_facil = mTCOff[:,facilitated_Ind]\n",
    "mTCOn_facil = mTCOn[:,facilitated_Ind]\n",
    "\n",
    "mTCOff_supp = mTCOff[:,suppressed_Ind]\n",
    "mTCOn_supp = mTCOn[:,suppressed_Ind]\n",
    "\n",
    "Late_mTCOff_facil = Late_mTCOff[:,facilitated_Ind]\n",
    "Late_mTCOn_facil = Late_mTCOn[:,facilitated_Ind]\n",
    "\n",
    "Late_mTCOff_supp = Late_mTCOff[:,suppressed_Ind]\n",
    "Late_mTCOn_supp = Late_mTCOn[:,suppressed_Ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Sparseness\n",
    "\n",
    "# Calculate for all cells\n",
    "SparsenessOff_all, SparsenessOn_all, Late_SparsenessOff_all, Late_SparsenessOn_all = calculate_sparseness(mTCOff, mTCOn, Late_mTCOff, Late_mTCOn)\n",
    "\n",
    "# Calculate for facilitated cells, ensure to replace mTCOff_facil/mTCOn_facil with your actual variables for facilitated cells\n",
    "SparsenessOff_facilitated, SparsenessOn_facilitated, Late_SparsenessOff_facilitated, Late_SparsenessOn_facilitated = calculate_sparseness(mTCOff_facil, mTCOn_facil, Late_mTCOff_facil, Late_mTCOn_facil)\n",
    "\n",
    "# Calculate for suppressed cells, ensure to replace mTCOff_supp/mTCOn_supp with your actual variables for suppressed cells\n",
    "SparsenessOff_suppressed, SparsenessOn_suppressed, Late_SparsenessOff_suppressed, Late_SparsenessOn_suppressed = calculate_sparseness(mTCOff_supp, mTCOn_supp, Late_mTCOff_supp, Late_mTCOn_supp)\n",
    "\n",
    "# Example of filtering NaNs for one of the results if needed\n",
    "late_Spars_on_supp = np.asarray(Late_SparsenessOn_suppressed)\n",
    "Late_SparsenessOn_suppressed_filt = late_Spars_on_supp[~np.isnan(late_Spars_on_supp)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mTCOff_facil_norm = mTCOff_norm[:,facilitated_Ind]\n",
    "mTCOn_facil_norm = mTCOn_norm[:,facilitated_Ind]\n",
    "\n",
    "mTCOff_supp_norm = mTCOff_norm[:,suppressed_Ind]\n",
    "mTCOn_supp_norm = mTCOn_norm[:,suppressed_Ind]\n",
    "\n",
    "Late_mTCOff_facil_norm = Late_mTCOff_norm[:,facilitated_Ind]\n",
    "Late_mTCOn_facil_norm = Late_mTCOn_norm[:,facilitated_Ind]\n",
    "\n",
    "Late_mTCOff_supp_norm = Late_mTCOff_norm[:,suppressed_Ind]\n",
    "Late_mTCOn_supp_norm = Late_mTCOn_norm[:,suppressed_Ind]\n",
    "\n",
    "y_pred_facil = y_pred[:,facilitated_Ind]\n",
    "y_pred_supp = y_pred[:,suppressed_Ind]\n",
    "\n",
    "Late_y_pred_facil = Late_y_pred[:,facilitated_Ind]\n",
    "Late_y_pred_supp = Late_y_pred[:,suppressed_Ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best frequency and the unpreferred frequency\n",
    "sideFreq = 4\n",
    "octaves = np.log2(uniq_Freq[4:13]) - np.log2(uniq_Freq[8])\n",
    "\n",
    "# For all cells dataset\n",
    "BF, FR_BF, cFR, cFR_On, uBF, FR_uBF, cFR_uBF, cFR_On_uBF = get_BF_and_uBF(mTCOff, mTCOn, uniq_Freq, sideFreq)\n",
    "\n",
    "# For the facilitated datasets\n",
    "BF_facil, FR_BF_facil, cFR_facil, cFR_On_facil, uBF_facil, FR_uBF_facil, cFR_uBF_facil, cFR_On_uBF_facil = get_BF_and_uBF(mTCOff_facil, mTCOn_facil, uniq_Freq, sideFreq)\n",
    "\n",
    "# For the suppressed datasets\n",
    "BF_supp, FR_BF_supp, cFR_supp, cFR_On_supp, uBF_supp, FR_uBF_supp, cFR_uBF_supp, cFR_On_uBF_supp = get_BF_and_uBF(mTCOff_supp, mTCOn_supp, uniq_Freq, sideFreq)\n",
    "\n",
    "\n",
    "# For all cells datasets using \"Late\" time point\n",
    "Late_BF, Late_FR_BF, Late_cFR, Late_cFR_On, Late_uBF, Late_FR_uBF, Late_cFR_uBF, Late_cFR_On_uBF = get_BF_and_uBF(Late_mTCOff, Late_mTCOn, uniq_Freq, sideFreq)\n",
    "\n",
    "# For the facilitated datasets using \"Late\" time point\n",
    "Late_BF_facil, Late_FR_BF_facil, Late_cFR_facil, Late_cFR_On_facil, Late_uBF_facil, Late_FR_uBF_facil, Late_cFR_uBF_facil, Late_cFR_On_uBF_facil = get_BF_and_uBF(Late_mTCOff_facil, Late_mTCOn_facil, uniq_Freq, sideFreq)\n",
    "\n",
    "# For the suppressed datasets using \"Late\" time point\n",
    "Late_BF_supp, Late_FR_BF_supp, Late_cFR_supp, Late_cFR_On_supp, Late_uBF_supp, Late_FR_uBF_supp, Late_cFR_uBF_supp, Late_cFR_On_uBF_supp = get_BF_and_uBF(Late_mTCOff_supp, Late_mTCOn_supp, uniq_Freq, sideFreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SEM for non-normalized tone-only significantdata \n",
    "errorOff_toneOnly = calculate_sem(meanLaserOff_toneonly_masked)\n",
    "errorOn_toneOnly = calculate_sem(meanLaserOn_toneonly_masked)\n",
    "\n",
    "# Calculate SEM for normalized tone-only significant data\n",
    "errorOff_n_toneOnly = calculate_sem(norm_PSTH_OFF_toneonly_masked)\n",
    "errorOn_n_toneOnly = calculate_sem(norm_PSTH_On_toneonly_masked)\n",
    "\n",
    "errorLaserOnly_toneOnly = calculate_sem(toneOnlyRespPSTH_Laser.mean(axis=0))\n",
    "\n",
    "\n",
    "# Calculate SEM for non-normalized data\n",
    "errorOff = calculate_sem(meanLaserOff_masked)\n",
    "errorOn = calculate_sem(meanLaserOn_masked)\n",
    "\n",
    "# Calculate SEM for normalized data\n",
    "errorOff_n = calculate_sem(norm_PSTH_OFF_masked)\n",
    "errorOn_n = calculate_sem(norm_PSTH_On_masked)\n",
    "\n",
    "errorLaserOnly = calculate_sem(toneRespPSTH_Laser.mean(axis=0))\n",
    "\n",
    "# Calculate SEM for both groups for raw firing rates & normalized firing rates\n",
    "errorlasfacil = calculate_sem(toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind])\n",
    "errorlassupp = calculate_sem(toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind])\n",
    "\n",
    "errorOff_facil = calculate_sem(facilitated_cells_Off)\n",
    "errorOn_facil = calculate_sem(facilitated_cells_On)\n",
    "\n",
    "errorOff_supp = calculate_sem(suppressed_cells_Off)\n",
    "errorOn_supp = calculate_sem(suppressed_cells_On)\n",
    "\n",
    "errorOff_facil_norm = calculate_sem(facilitated_cells_Off_norm)\n",
    "errorOn_facil_norm = calculate_sem(facilitated_cells_On_norm)\n",
    "\n",
    "errorOff_supp_norm = calculate_sem(suppressed_cells_Off_norm)\n",
    "errorOn_supp_norm = calculate_sem(suppressed_cells_On_norm)\n",
    "\n",
    "\n",
    "# Calculate errors using the function\n",
    "errorOff_tc_facil = calculate_sem(cFR_facil)\n",
    "errorOn_tc_facil = calculate_sem(cFR_On_facil)\n",
    "\n",
    "errorOff_tc_supp = calculate_sem(cFR_supp)\n",
    "errorOn_tc_supp = calculate_sem(cFR_On_supp)\n",
    "\n",
    "Late_errorOff_tc_facil = calculate_sem(Late_cFR_facil)\n",
    "Late_errorOn_tc_facil = calculate_sem(Late_cFR_On_facil)\n",
    "\n",
    "Late_errorOff_tc_supp = calculate_sem(Late_cFR_supp)\n",
    "Late_errorOn_tc_supp = calculate_sem(Late_cFR_On_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find peaks ?\n",
    "pOn = []\n",
    "pOnInd = []\n",
    "pOff = []\n",
    "for cell in range(len(toneRespPSTH[0][0])):\n",
    "#     fig, ax = plt.subplots()\n",
    "    pOn_t,_ = signal.find_peaks(meanLaserOn_masked[early_evoked_Ind,cell], height= \\\n",
    "                               (np.mean(meanLaserOn_masked[spontInd,cell]) +\\\n",
    "                                (np.std(meanLaserOn_masked[spontInd,cell])*3)))\n",
    "    pOn.append(pOn_t)\n",
    "    if len(pOn_t) == 0:\n",
    "        pOn_tI = 0\n",
    "    else:\n",
    "        pOn_tI = 1\n",
    "    \n",
    "    pOnInd.append(pOn_tI)\n",
    "\n",
    "\n",
    "    pOff_t,_ = signal.find_peaks(meanLaserOff_masked[early_evoked_Ind,cell], height= \\\n",
    "                                    (np.mean(meanLaserOff_masked[spontInd,cell]) +\\\n",
    "                                    (np.std(meanLaserOff_masked[spontInd,cell])*3)))\n",
    "    pOff.append(pOff_t)\n",
    "\n",
    "peakInd=np.squeeze(np.where(np.asarray(pOnInd)==1))\n",
    "\n",
    "facil_peakInd, _, _ = np.intersect1d(facilitated_Ind,peakInd,return_indices=True)\n",
    "supp_peakInd, _, _ = np.intersect1d(suppressed_Ind,peakInd,return_indices=True)\n",
    "\n",
    "peakCellstuseOn = meanLaserOn_masked[:,peakInd]\n",
    "peakCellstuseOff = meanLaserOff_masked[:,peakInd]\n",
    "\n",
    "peakCellstuseOn_facil = meanLaserOn_masked[:,facil_peakInd]\n",
    "peakCellstuseOff_facil = meanLaserOff_masked[:,facil_peakInd]\n",
    "\n",
    "peakCellstuseOn_supp = meanLaserOn_masked[:,supp_peakInd]\n",
    "peakCellstuseOff_supp = meanLaserOff_masked[:,supp_peakInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrames\n",
    "df_diff_Sorted_facil = pd.DataFrame(diff_Sorted_facil, columns=['Diff Sorted Facil'])\n",
    "df_diff_Sorted_supp = pd.DataFrame(diff_Sorted_supp, columns=['Diff Sorted Supp'])\n",
    "df_facilitated_depths = pd.DataFrame(facilitated_depths, columns=['Facilitated Depths Column1', 'Facilitated Depths Column2'])\n",
    "df_suppressed_depths = pd.DataFrame(suppressed_depths, columns=['Suppressed Depths Column1', 'Suppressed Depths Column2'])\n",
    "df_diff_resp_EarlyOn_array = pd.DataFrame(diff_resp_EarlyOn_array, columns=['Diff Resp Early On'])\n",
    "df_Clust_Depth_toneResp = pd.DataFrame(Clust_Depth_toneResp, columns=['Clust Depth ToneResp Column1', 'Clust Depth ToneResp Column2'])\n",
    "\n",
    "# Export to CSV\n",
    "df_diff_Sorted_facil.to_csv('diff_Sorted_facil.csv', index=True)\n",
    "df_diff_Sorted_supp.to_csv('diff_Sorted_supp.csv', index=False)\n",
    "df_facilitated_depths.to_csv('facilitated_depths.csv', index=False)\n",
    "df_suppressed_depths.to_csv('suppressed_depths.csv', index=False)\n",
    "df_diff_resp_EarlyOn_array.to_csv('diff_resp_EarlyOn_array.csv', index=False)\n",
    "df_Clust_Depth_toneResp.to_csv('Clust_Depth_toneResp.csv', index=False)\n",
    "\n",
    "# Save CSV files in the specified directory\n",
    "csv_files = {\n",
    "    'diff_Sorted_facil.csv': df_diff_Sorted_facil,\n",
    "    'diff_Sorted_supp.csv': df_diff_Sorted_supp,\n",
    "    'facilitated_depths.csv': df_facilitated_depths,\n",
    "    'suppressed_depths.csv': df_suppressed_depths,\n",
    "    'diff_resp_EarlyOn_array.csv': df_diff_resp_EarlyOn_array,\n",
    "    'Clust_Depth_toneResp.csv': df_Clust_Depth_toneResp\n",
    "}\n",
    "\n",
    "for filename, dataframe in csv_files.items():\n",
    "    full_path = os.path.join(fig_dir_time, filename)  # Create full file path\n",
    "    dataframe.to_csv(full_path, index=False)  # Save to CSV without the index\n",
    "\n",
    "print(\"CSV files have been saved in:\", fig_dir_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average PSTH for all cells.\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_size_inches(6,3)\n",
    "\n",
    "ax[0].plot(time, meanLaserOff_masked.mean(axis=1),c=_new_black)\n",
    "ax[0].plot(time, meanLaserOn_masked.mean(axis=1),'CornflowerBlue')\n",
    "ax[0].axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax[0].axvline(x=tDur,ls='--', c=_new_black)\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "ax[0].set_ylabel('FR (Hz)')\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].fill_between(time, meanLaserOff_masked.mean(axis=1)-errorOff, meanLaserOff_masked.mean(axis=1)+errorOff,\\\n",
    "                  alpha=0.5, facecolor= _new_black)\n",
    "ax[0].fill_between(time, meanLaserOn_masked.mean(axis=1)-errorOn, meanLaserOn_masked.mean(axis=1)+errorOn,\\\n",
    "                  alpha=0.5, facecolor='CornflowerBlue') \n",
    "\n",
    "ax[0].fill_between(time, toneRespPSTH_Laser.mean(axis=0).mean(axis=1)-errorLaserOnly, toneRespPSTH_Laser.mean(axis=0).mean(axis=1)+errorLaserOnly,\\\n",
    "                  alpha=0.5, facecolor='seagreen') \n",
    "\n",
    "ax[0].set_yticks(np.ceil(ax[0].get_yticks()/10) * 10)\n",
    "ymin0, ymax0 = ax[0].get_ylim()\n",
    "ax[0].set_ylim(0, ymax0)\n",
    "ax[0].yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax[0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0].set_xlim(np.min(time), np.max(time))\n",
    "ax[0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax[0].xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax[0].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[0].tick_params(which='major', color=_new_black)\n",
    "ax[0].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax[1].plot(time, norm_PSTH_OFF_masked.mean(axis=1),c=_new_black)\n",
    "ax[1].plot(time, norm_PSTH_On_masked.mean(axis=1),'CornflowerBlue')\n",
    "ax[1].axvline(x=tStart,ls='--',c=_new_black)\n",
    "ax[1].axvline(x=tDur,ls='--', c=_new_black)\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "ax[1].set_ylabel('Normalized FR')\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "\n",
    "ax[1].fill_between(time, norm_PSTH_OFF_masked.mean(axis=1)-errorOff_n, norm_PSTH_OFF_masked.mean(axis=1)+errorOff_n,\\\n",
    "                  alpha=0.5, facecolor=_new_black)\n",
    "ax[1].fill_between(time, norm_PSTH_On_masked.mean(axis=1)-errorOn_n, norm_PSTH_On_masked.mean(axis=1)+errorOn_n,\\\n",
    "                  alpha=0.5, facecolor='CornflowerBlue')\n",
    "ax[1].set_yticks(np.round(ax[1].get_yticks(),1))\n",
    "ymin1, ymax1 = ax[1].get_ylim()\n",
    "ax[1].set_ylim(0, ymax1)\n",
    "ax[1].yaxis.set_major_locator(ticker.MultipleLocator(.1))\n",
    "ax[1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[1].set_xlim(np.min(time), np.max(time))\n",
    "ax[1].xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax[1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax[1].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[1].tick_params(which='major', color=_new_black)\n",
    "ax[1].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax[2].plot(time, toneRespPSTH_Laser.mean(axis=0).mean(axis=1),c=_new_black)\n",
    "ax[2].axvline(x=laserStart,ls='--', c=_new_black)\n",
    "ax[2].axvline(x=laserOnlyDur,ls='--', c=_new_black)\n",
    "ax[2].set_xlabel('Time (s)')\n",
    "ax[2].set_ylabel('FR (Hz)')\n",
    "ax[2].spines['right'].set_visible(False)\n",
    "ax[2].spines['top'].set_visible(False)\n",
    "ax[2].set_yticks(np.ceil(ax[2].get_yticks()/10) * 10)\n",
    "ymin2, ymax2 = ax[2].get_ylim()\n",
    "ax[2].set_ylim(0, ymax2)\n",
    "ax[2].yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax[2].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[2].set_xlim(np.min(time), np.max(time))\n",
    "ax[2].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax[2].xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax[2].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[2].tick_params(which='major', color=_new_black)\n",
    "ax[2].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax[0].set_box_aspect(.6)\n",
    "ax[1].set_box_aspect(.6)\n",
    "ax[2].set_box_aspect(.6)\n",
    "\n",
    "\n",
    "ax[0].spines['left'].set_bounds((0, ymax0))\n",
    "ax[1].spines['left'].set_bounds((0, ymax1))\n",
    "ax[2].spines['left'].set_bounds((0, ymax2))\n",
    "\n",
    "ax[0].set_title('Mean PSTH')\n",
    "ax[1].set_title('Mean Normalized PSTH')\n",
    "ax[2].set_title('Mean PSTH Laser Only')\n",
    "\n",
    "\n",
    "fig.align_ylabels(ax[:])\n",
    "fig.align_xlabels(ax[:])\n",
    "\n",
    "plot_name = \"Mean_PSTH_AllCells_%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot scatter plots of firing rates during tone presentation in laserOff and laserOn conditions.\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(4, 1.5)\n",
    "\n",
    "# First subplot\n",
    "ax[0].scatter(meanLaserOff_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "              meanLaserOn_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "              s=0.25, c=_new_black, facecolor=_new_black)\n",
    "ax[0].plot([0, 1], [0, 1], transform=ax[0].transAxes, color='dimgrey', ls=\"--\")\n",
    "ax[0].set_xlabel('FR$_{Off}$')\n",
    "ax[0].set_ylabel('FR$_{On}$')\n",
    "\n",
    "# Adding a best fit line to the first subplot\n",
    "m, b = np.polyfit(meanLaserOff_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "                  meanLaserOn_masked[early_evoked_Ind, :].mean(axis=0), 1)\n",
    "ax[0].plot(meanLaserOff_masked[early_evoked_Ind, :].mean(axis=0), m * meanLaserOff_masked[early_evoked_Ind, :].mean(axis=0) + b, 'CornflowerBlue')\n",
    "\n",
    "# Setting ticks and limits for the first subplot\n",
    "ax[0].set_ylim(0, 100)\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "# Second subplot\n",
    "ax[1].scatter(norm_PSTH_OFF_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "              norm_PSTH_On_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "              s=0.25, c=_new_black, facecolor=_new_black)\n",
    "ax[1].plot([0, 1], [0, 1], transform=ax[1].transAxes, color='dimgrey', ls=\"--\")\n",
    "ax[1].set_xlabel('Normalized FR$_{Off}$')\n",
    "ax[1].set_ylabel('Normalized FR$_{On}$')\n",
    "\n",
    "# Adding a best fit line to the second subplot\n",
    "m_norm, b_norm = np.polyfit(norm_PSTH_OFF_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "                            norm_PSTH_On_masked[early_evoked_Ind, :].mean(axis=0), 1)\n",
    "ax[1].plot(norm_PSTH_OFF_masked[early_evoked_Ind, :].mean(axis=0), m_norm * norm_PSTH_OFF_masked[early_evoked_Ind, :].mean(axis=0) + b_norm, 'CornflowerBlue')\n",
    "\n",
    "# Setting ticks and limits for the second subplot\n",
    "ax[1].set_ylim(0, 1)\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[1].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "\n",
    "# Ensuring equal aspect ratio for both subplots\n",
    "ax[0].set_box_aspect(1)\n",
    "ax[1].set_box_aspect(1)\n",
    "\n",
    "# Aligning labels\n",
    "fig.align_ylabels(ax[:])\n",
    "fig.align_xlabels(ax[:])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_name = f\"ScatterPlots_Evoked_{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name), bbox_inches='tight', dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plots of firing rates during laser presentation and spontaneous activity.\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(2, 1.5)\n",
    "\n",
    "# Scatter plot with customized settings\n",
    "ax.scatter(PSTH_Laser_norm_masked[spontInd, :].mean(axis=0), \n",
    "           PSTH_Laser_norm_masked[early_evoked_Ind, :].mean(axis=0), \n",
    "           s=0.25, c=_new_black, facecolor=_new_black, rasterized=True)\n",
    "\n",
    "# Diagonal line indicating y=x for reference\n",
    "ax.plot([0, 1], [0, 1], color='dimgrey', ls=\"--\")\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('Normalized FR$_{Spontaneous}$')\n",
    "ax.set_ylabel('Normalized FR$_{On}$')\n",
    "\n",
    "# Directly set limits and major tick formatting\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "\n",
    "# Minor tick adjustments\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.tick_params(which='major', color=_new_black)\n",
    "ax.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "# Ensure square aspect ratio\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "# Save the figure\n",
    "plot_name = f\"ScatterPlot_LaserOnly_{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name), bbox_inches='tight', dpi=600, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pie chart for facilitated and suppressed cells:\n",
    "pie_data = [len(facilitated_Ind), len(suppressed_Ind), len(toneIndex)]\n",
    "pie_data\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(4,3)\n",
    "labels = 'Facilitated', 'Suppressed', 'Non-Significant'\n",
    "colors = ['#002c94','#85000c','#787586']\n",
    "patches, texts, pcts =ax.pie(pie_data,labels=labels, wedgeprops={'linewidth':1.5, 'edgecolor':'white'}, startangle = 25,\\\n",
    "         colors = colors,autopct='%.0f%%')\n",
    "plt.setp(pcts, color='white')\n",
    "\n",
    "plot_name = \"PieChart_%s.pdf\"%cellType\n",
    "\n",
    "fig.savefig(os.path.join(fig_dir_time,\"PieChart.pdf\"), bbox_inches='tight', dpi=600, transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot mean PSTH for the separated groups during tone-presentation & laser only:\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "fig.set_size_inches(4,3)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1], sharey=ax0, sharex=ax0)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax3 = fig.add_subplot(gs[1, 1], sharey=ax1, sharex=ax1)\n",
    "\n",
    "\n",
    "ax0.plot(time,facilitated_cells_Off.mean(axis = 1),c=_new_black)\n",
    "ax0.plot(time, facilitated_cells_On.mean(axis = 1),'CornflowerBlue')\n",
    "ax0.plot(time, toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind].mean(axis=1),c='seagreen')\n",
    "ax0.axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax0.axvline(x=tDur,ls='--', c=_new_black)\n",
    "ax0.legend(['Laser Off','Laser On','Laser Only'])\n",
    "ax0.set_title('Facilitated Neurons')\n",
    "ax0.set_xlabel('Time (s)')\n",
    "ax0.set_ylabel('FR (Hz)')\n",
    "ax0.spines['right'].set_visible(False)\n",
    "ax0.spines['top'].set_visible(False)\n",
    "ax0.fill_between(time, facilitated_cells_Off.mean(axis=1)-errorOff_facil, \\\n",
    "                   facilitated_cells_Off.mean(axis=1)+errorOff_facil,\\\n",
    "                  alpha=0.5, facecolor=_new_black)\n",
    "ax0.fill_between(time, facilitated_cells_On.mean(axis=1)-errorOn_facil, \\\n",
    "                   facilitated_cells_On.mean(axis=1)+errorOn_facil,\\\n",
    "                  alpha=0.5, facecolor='CornflowerBlue')\n",
    "ax0.fill_between(time, toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind].mean(axis=1)-errorlasfacil, \\\n",
    "                   toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind].mean(axis=1)+errorlasfacil,\\\n",
    "                  alpha=0.5, facecolor='seagreen') \n",
    "ax0.set_yticks(np.floor(ax0.get_yticks()/20) * 20)\n",
    "ymin0, ymax0 = ax0.get_ylim()\n",
    "ax0.set_ylim(0, ymax0)\n",
    "ax0.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax0.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax0.set_xlim(np.min(time), np.max(time))\n",
    "ax0.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax0.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax0.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax0.tick_params(which='major', color=_new_black)\n",
    "ax0.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax1.plot(time,suppressed_cells_Off.mean(axis = 1),c=_new_black)\n",
    "ax1.plot(time, suppressed_cells_On.mean(axis = 1),'CornflowerBlue')\n",
    "ax1.plot(time, toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind].mean(axis=1),c='seagreen')\n",
    "ax1.axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax1.axvline(x=tDur,ls='--', c=_new_black)\n",
    "ax1.legend(['Laser Off','Laser On'])\n",
    "ax1.set_title('Suppressed Neurons')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('FR (Hz)')\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.fill_between(time, suppressed_cells_Off.mean(axis=1)-errorOff_supp, \\\n",
    "                   suppressed_cells_Off.mean(axis=1)+errorOff_supp,\\\n",
    "                  alpha=0.5, facecolor=_new_black)\n",
    "ax1.fill_between(time, suppressed_cells_On.mean(axis=1)-errorOn_supp, \\\n",
    "                   suppressed_cells_On.mean(axis=1)+errorOn_supp,\\\n",
    "                  alpha=0.5, facecolor='CornflowerBlue')\n",
    "ax1.fill_between(time, toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind].mean(axis=1)-errorlassupp, \\\n",
    "                   toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind].mean(axis=1)+errorlassupp,\\\n",
    "                  alpha=0.5, facecolor='seagreen') \n",
    "ax1.set_yticks(np.floor(ax1.get_yticks()/20) * 20)\n",
    "ymin1, ymax1 = ax1.get_ylim()\n",
    "ax1.set_ylim(0, ymax1)\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax1.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax1.set_xlim(np.min(time), np.max(time))\n",
    "ax1.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax1.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax1.tick_params(which='major', color=_new_black)\n",
    "ax1.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax2.plot(time, toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind].mean(axis=1),c=_new_black)\n",
    "ax2.fill_between(time, toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind].mean(axis=1)-errorlasfacil, \\\n",
    "                   toneRespPSTH_Laser.mean(axis=0)[:,facilitated_Ind].mean(axis=1)+errorlasfacil,\\\n",
    "                  alpha=0.5, facecolor=_new_black)\n",
    "ax2.axvline(x=laserStart,ls='--', c=_new_black)\n",
    "ax2.axvline(x=laserOnlyDur,ls='--', c=_new_black)\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('FR (Hz)')\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.set_yticks(np.ceil(ax2.get_yticks()/20) * 20)\n",
    "ymin2, ymax2 = ax2.get_ylim()\n",
    "ax2.set_ylim(0, ymax2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax2.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax2.set_xlim(np.min(time), np.max(time))\n",
    "ax2.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax2.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax2.tick_params(which='major', color=_new_black)\n",
    "ax2.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax3.plot(time, toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind].mean(axis=1),c=_new_black)\n",
    "ax3.fill_between(time, toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind].mean(axis=1)-errorlassupp, \\\n",
    "                   toneRespPSTH_Laser.mean(axis=0)[:,suppressed_Ind].mean(axis=1)+errorlassupp,\\\n",
    "                  alpha=0.5, facecolor=_new_black)\n",
    "ax3.axvline(x=laserStart,ls='--', c=_new_black)\n",
    "ax3.axvline(x=laserOnlyDur,ls='--', c=_new_black)\n",
    "ax3.set_xlabel('Time (s)')\n",
    "ax3.set_ylabel('FR (Hz)')\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.set_yticks(np.ceil(ax3.get_yticks()/20) * 20)\n",
    "ymin3, ymax3 = ax3.get_ylim()\n",
    "ax3.set_ylim(0, ymax3)\n",
    "ax3.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax3.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax3.set_xlim(np.min(time), np.max(time))\n",
    "ax3.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax3.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax3.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax3.tick_params(which='major', color=_new_black)\n",
    "ax3.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax0.set_box_aspect(.6)\n",
    "ax1.set_box_aspect(.6)\n",
    "ax2.set_box_aspect(.6)\n",
    "ax3.set_box_aspect(.6)\n",
    "\n",
    "\n",
    "fig.align_ylabels([ax0,ax1,ax2,ax3])\n",
    "fig.align_xlabels([ax0,ax1,ax2,ax3])\n",
    "\n",
    "plot_name = \"MeanPSTH_Divided_%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram demonstrating the difference in firing rates:\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "# Clip values and calculate bins directly within the hist function for brevity\n",
    "bins = np.arange(-1.5, 1.5 + 0.071, 0.071)\n",
    "ax.hist(np.clip(diff_resp_norm_EarlyOn_array, -1.5, 1.5), bins=bins, color=\"#787586\", edgecolor=\"#787586\")\n",
    "\n",
    "# Simplifying axvline and labels in a compact way\n",
    "ax.axvline(x=0, color=_new_black, linestyle='--')\n",
    "ax.set(xlabel=r'Response Laser$_{On}$ - Response Laser$_{Off}$', ylabel='Cell Count', axisbelow=True)\n",
    "\n",
    "# Minor grid, tick, and aspect adjustments can be made more concise\n",
    "ax.grid(linestyle='--', which='both')\n",
    "ax.tick_params(which='major', color=_new_black)\n",
    "ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "\n",
    "plot_name = f\"Histogram_Diff_{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot scatter plot with differentiated groups with normalized firing rates:\n",
    "colors_ind = ['#002c94' if diff > 0 else '#85000c' if diff < 0 else '#787586' for diff in diff_resp_norm_EarlyOn_array]\n",
    "\n",
    "# Plot scatter plot with differentiated groups for all the time points:\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_size_inches(4,3)\n",
    "ax[0,0].scatter(meanLaserOff_masked[spontInd,:].mean(axis=0), \\\n",
    "           meanLaserOn_masked[spontInd,:].mean(axis=0), s=.25, color=colors_ind)\n",
    "ax[0,0].plot([0,1],[0,1], transform=ax[0,0].transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[0,0].set_title('Spontaneous Response')\n",
    "ax[0,0].set_xlabel('FR Off (Hz)')\n",
    "ax[0,0].set_ylabel('FR On (Hz)')\n",
    "\n",
    "\n",
    "ax[0,1].scatter(meanLaserOff_masked[early_evoked_Ind,:].mean(axis=0), \\\n",
    "           meanLaserOn_masked[early_evoked_Ind,:].mean(axis=0), s=.25, color=colors_ind)\n",
    "ax[0,1].plot([0,1],[0,1], transform=ax[0,1].transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[0,1].set_title('0-25ms Tone On')\n",
    "ax[0,1].set_xlabel('FR Off (Hz)')\n",
    "ax[0,1].set_ylabel('FR On (Hz)')\n",
    "\n",
    "\n",
    "ax[1,0].scatter(meanLaserOff_masked[late_evoked_Ind,:].mean(axis=0), \\\n",
    "           meanLaserOn_masked[late_evoked_Ind,:].mean(axis=0), s=.25, color=colors_ind)\n",
    "ax[1,0].plot([0,1],[0,1], transform=ax[1,0].transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[1,0].set_title('25-50ms Tone On')\n",
    "ax[1,0].set_xlabel('FR Off (Hz)', loc = 'center')\n",
    "ax[1,0].set_ylabel('FR On (Hz)', loc = 'center')\n",
    "\n",
    "\n",
    "ax[1,1].scatter(meanLaserOff_masked[offsetInd,:].mean(axis=0), \\\n",
    "           meanLaserOn_masked[offsetInd,:].mean(axis=0), s=.25, color=colors_ind)\n",
    "ax[1,1].plot([0,1],[0,1], transform=ax[1,1].transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[1,1].set_title('Offset Response')\n",
    "ax[1,1].set_xlabel('FR Off (Hz)')\n",
    "ax[1,1].set_ylabel('FR On (Hz)')\n",
    "\n",
    "\n",
    "m_Scat, b_Scat = np.polyfit(meanLaserOff_masked[early_evoked_Ind,:].mean(axis=0)\\\n",
    "                            ,meanLaserOn_masked[early_evoked_Ind,:].mean(axis=0),1)\n",
    "\n",
    "ax[0,1].plot(meanLaserOff_masked[early_evoked_Ind,:].mean(axis=0),  m_Scat*meanLaserOff_masked[early_evoked_Ind,:].mean(axis=0)\\\n",
    "           +  b_Scat, 'CornflowerBlue')\n",
    "\n",
    "m_Scat1, b_Scat1 = np.polyfit(meanLaserOff_masked[late_evoked_Ind,:].mean(axis=0)\\\n",
    "                            ,meanLaserOn_masked[late_evoked_Ind,:].mean(axis=0),1)\n",
    "\n",
    "ax[1,0].plot(meanLaserOff_masked[late_evoked_Ind,:].mean(axis=0),  m_Scat1*meanLaserOff_masked[late_evoked_Ind,:].mean(axis=0)\\\n",
    "           +  b_Scat1, 'CornflowerBlue')\n",
    "\n",
    "m_Scat2, b_Scat2 = np.polyfit(meanLaserOff_masked[offsetInd,:].mean(axis=0)\\\n",
    "                            ,meanLaserOn_masked[offsetInd,:].mean(axis=0),1)\n",
    "\n",
    "ax[1,1].plot(meanLaserOff_masked[offsetInd,:].mean(axis=0),  m_Scat2*meanLaserOff_masked[offsetInd,:].mean(axis=0)\\\n",
    "           +  b_Scat2, 'CornflowerBlue')\n",
    "\n",
    "m_Scat3, b_Scat3 = np.polyfit(meanLaserOff_masked[spontInd,:].mean(axis=0)\\\n",
    "                            ,meanLaserOn_masked[spontInd,:].mean(axis=0),1)\n",
    "\n",
    "ax[0,0].plot(meanLaserOff_masked[spontInd,:].mean(axis=0),  m_Scat3*meanLaserOff_masked[spontInd,:].mean(axis=0)\\\n",
    "           +  b_Scat3, 'CornflowerBlue')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[0,0].set_yticks(np.ceil(ax[0,0].get_yticks()/10) * 10)\n",
    "ymin0, ymax0 = ax[0,0].get_ylim()\n",
    "ax[0,0].set_ylim(0, 100)\n",
    "ax[0,0].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0,0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0,0].set_xticks(np.ceil(ax[0,0].get_xticks()/10) * 10)\n",
    "xmin0, xmax0 = ax[0,0].get_xlim()\n",
    "ax[0,0].set_xlim(0, 100)\n",
    "ax[0,0].xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0,0].tick_params(which='major', color=_new_black)\n",
    "ax[0,0].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "ax[0,1].set_yticks(np.ceil(ax[0,1].get_yticks()/10) * 10)\n",
    "ymin1, ymax1 = ax[0,1].get_ylim()\n",
    "ax[0,1].set_ylim(0, 100)\n",
    "ax[0,1].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0,1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0,1].set_xticks(np.ceil(ax[0,1].get_xticks()/10) * 10)\n",
    "xmin1, xmax1 = ax[0,1].get_xlim()\n",
    "ax[0,1].set_xlim(0, 100)\n",
    "ax[0,1].xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0,1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0,1].tick_params(which='major', color=_new_black)\n",
    "ax[0,1].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[1,0].set_yticks(np.ceil(ax[1,0].get_yticks()/10) * 10)\n",
    "ymin2, ymax2 = ax[1,0].get_ylim()\n",
    "ax[1,0].set_ylim(0, 100)\n",
    "ax[1,0].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[1,0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[1,0].set_xticks(np.ceil(ax[1,0].get_xticks()/10) * 10)\n",
    "xmin2, xmax2 = ax[1,0].get_xlim()\n",
    "ax[1,0].set_xlim(0, 100)\n",
    "ax[1,0].xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[1,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[1,0].tick_params(which='major', color=_new_black)\n",
    "ax[1,0].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[1,1].set_yticks(np.ceil(ax[1,1].get_yticks()/10) * 10)\n",
    "ymin3, ymax3 = ax[1,1].get_ylim()\n",
    "ax[1,1].set_ylim(0, 100)\n",
    "ax[1,1].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[1,1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax[1,1].set_xticks(np.ceil(ax[1,1].get_xticks()/10) * 10)\n",
    "xmin3, xmax3 = ax[1,1].get_xlim()\n",
    "ax[1,1].set_xlim(0, 100)\n",
    "ax[1,1].xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[1,1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[1,1].tick_params(which='major', color=_new_black)\n",
    "ax[1,1].tick_params(which='minor', color=_new_black)\n",
    "ax[0,0].spines['left'].set_bounds((0, 100))\n",
    "ax[0,1].spines['left'].set_bounds((0, 100))\n",
    "ax[1,0].spines['left'].set_bounds((0, 100))\n",
    "ax[1,1].spines['left'].set_bounds((0, 100))\n",
    "\n",
    "\n",
    "\n",
    "ax[0,0].set_box_aspect(1)\n",
    "ax[0,1].set_box_aspect(1)\n",
    "ax[1,0].set_box_aspect(1)\n",
    "ax[1,1].set_box_aspect(1)\n",
    "\n",
    "fig.align_ylabels(ax[:])\n",
    "fig.align_xlabels(ax[:])\n",
    "\n",
    "\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='.',color='#002c94', label='Facilitated Units', markerfacecolor='#002c94', markersize=5, linestyle = 'None'),\\\n",
    "                   Line2D([0], [0], marker='.', color='#85000c', label='Suppressed Units',markerfacecolor='#85000c', markersize=5,linestyle = 'None'),\\\n",
    "                   Line2D([0], [0], marker='.', color='#787586', label='No Significant Laser Effect', markerfacecolor='#787586', markersize=5,linestyle = 'None')]\n",
    "\n",
    "# Adjust the legend placement\n",
    "fig.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1,0.5), frameon=False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_name = \"ScatterPlots_AllTimes_RawFR%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot bar plots showing Firing rates during laser off and laser on trials during the spontaneous, evoked and late-evoked time:\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 2))  # Adjusting figsize for horizontal layout\n",
    "\n",
    "# Common properties and customizations\n",
    "boxprops = dict(linewidth=.2, color=_new_black)\n",
    "capprops = dict(linestyle='-', linewidth=0.5)\n",
    "medianprops = dict(linestyle='-', color=_new_black, linewidth=0.25)\n",
    "whiskerprops = dict(linestyle='-', color=_new_black, linewidth=0.25)\n",
    "meanpointprops = dict(marker='.', markeredgecolor='#f7ab31', markerfacecolor='#f7ab31', linewidth=0.25, markersize=.25)\n",
    "colors = [['#002c94', 'CornflowerBlue', '#85000c', 'CornflowerBlue'],\n",
    "          ['#4C6BB4', '#92B4F2', '#A94C54', '#92B4F2'],\n",
    "          ['#99AAD4', '#B2CAF5', '#C28187', '#B2CAF5']]\n",
    "titles = ['Early Evoked', 'Late Evoked', 'Spontaneous']\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    # Selecting the correct dataset for each subplot\n",
    "    if i == 0:\n",
    "        data_indices = early_evoked_Ind\n",
    "    elif i == 1:\n",
    "        data_indices = late_evoked_Ind\n",
    "    else:  # i == 2\n",
    "        data_indices = spontInd\n",
    "\n",
    "    data = [facilitated_cells_Off[data_indices, :].mean(axis=0), facilitated_cells_On[data_indices, :].mean(axis=0),\n",
    "            suppressed_cells_Off[data_indices, :].mean(axis=0), suppressed_cells_On[data_indices, :].mean(axis=0)]\n",
    "\n",
    "    # Creating the boxplot\n",
    "    bplot = ax.boxplot(data, notch=False, showmeans=True, patch_artist=True, meanprops=meanpointprops,\n",
    "                       meanline=False, medianprops=medianprops, positions=[0.15, .45, 1.05, 1.35],\n",
    "                       widths=0.20, boxprops=boxprops, capprops=capprops, showfliers=False, whiskerprops=whiskerprops)\n",
    "\n",
    "    ax.axvline(x=.75, color=_new_black, linestyle='--')\n",
    "    for patch, color in zip(bplot['boxes'], colors[i]):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    ax.set_yticks(np.floor(ax.get_yticks() / 10) * 10)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(0, ymax)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "    ax.set_ylabel('FR (Hz)')\n",
    "    ax.tick_params(which='major', color=_new_black)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_bounds((0, ymax))\n",
    "    ax.set_xlim([0, 2.5])\n",
    "    ax.set_xticklabels(['Off', 'On', 'Off', 'On'])\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "    if i == 0:  # Only add legend to the first plot (or choose according to preference)\n",
    "        ax.legend([*bplot[\"boxes\"]], ['Facilitated Off', 'Facilitated On', 'Suppressed Off', 'Suppressed On'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Assuming cellType and fig_dir_time are defined\n",
    "plot_name = \"FR_BPlot_Combined_%s.pdf\" % cellType\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pie chart with total percentage of cells\n",
    "pie_data_sort = [len(diff_Sorted_facil_norm), len(diff_Sorted_supp_norm)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(2,1.5)\n",
    "labels = 'Facilitated', 'Suppressed'\n",
    "colors = ['#002c94','#85000c','#787586']\n",
    "patches, texts, pcts =ax.pie(pie_data_sort,labels=labels, wedgeprops={'linewidth':1.5, 'edgecolor':'white'}, startangle = 25,\\\n",
    "         colors = colors,autopct='%.0f%%')\n",
    "plt.setp(pcts, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 2 rows and 3 columns of subplots\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(17, 11), constrained_layout=False)\n",
    "fig.tight_layout(pad=10)\n",
    "\n",
    "\n",
    "# Plot 1: scatter plot\n",
    "ax = axs[0, 0]\n",
    "ax.scatter(diff_resp_EarlyOn_array, depths_numeric, color='#787586', s=10)\n",
    "ax.invert_yaxis()\n",
    "# ax.set_ylim(-800, 25)\n",
    "# ax.set_xlim(-1.05, 1.05)\n",
    "ax.axvline(x=0, color='black', linestyle='--')\n",
    "ax.set_xlabel(r'$\\Delta$ FR (Hz)')\n",
    "ax.set_ylabel('Recording Depth (mm)')\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.set_title('Scatter plot of difference in FR')\n",
    "\n",
    "# Plot 2: Scatter plot with categories\n",
    "ax = axs[0, 1]\n",
    "ax.scatter(diff_Sorted_facil, depths_numeric_facil, color='#002c94', s=10, label='Facilitated')\n",
    "ax.scatter(diff_Sorted_supp, depths_numeric_supp, color='#85000c', s=10, label='Suppressed')\n",
    "ax.invert_yaxis()\n",
    "# ax.set_ylim(-800, 25)\n",
    "# ax.set_xlim(-1.05, 1.05)\n",
    "ax.axvline(x=0, color='black', linestyle='--')\n",
    "ax.set_xlabel(r'$\\Delta$ FR (Hz)')\n",
    "ax.set_ylabel('Recording Depth (mm)')\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.set_title('Categorized scatter plot of difference in FR')\n",
    "\n",
    "# Plot 3: Bar plot (aggregated mean)\n",
    "ax = axs[0, 2]\n",
    "ax.barh(bin_centers, facil_agg, height=bin_size * 0.4, label='Facilitated', color='#002c94')\n",
    "ax.barh(bin_centers, supp_agg, height=bin_size * 0.4, label='Suppressed', color='#85000c')\n",
    "ax.set_xlabel(r'Mean $\\Delta$ FR (Hz)')\n",
    "ax.set_ylabel('Recording Depth (mm)')\n",
    "ax.invert_yaxis()\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0)\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.set_title('Mean difference in FR per bin')\n",
    "\n",
    "\n",
    "# Plot 4: Bar plot (counts)\n",
    "ax = axs[1, 0]\n",
    "ax.barh(bin_centers, facil_counts, height=bin_size * 0.4, label='Facilitated', color='#002c94')\n",
    "ax.barh(bin_centers, -supp_counts, height=bin_size * 0.4, label='Suppressed', color='#85000c')\n",
    "ax.set_xlabel('Number of Cells')\n",
    "ax.set_ylabel('Recording Depth (mm)')\n",
    "ax.invert_yaxis()\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.set_title('Number of cells per bin')\n",
    "\n",
    "# Plot 5: Bar plot (sum)\n",
    "ax = axs[1, 1]\n",
    "ax.barh(bin_centers, facil_sum, height=bin_size * 0.4, label='Facilitated', color='#002c94')\n",
    "ax.barh(bin_centers, supp_sum, height=bin_size * 0.4, label='Suppressed', color='#85000c')\n",
    "ax.set_xlabel(r'$\\sum \\text{Mean } \\Delta \\text{FR (Hz)}$')\n",
    "ax.set_ylabel('Recording Depth (mm)')\n",
    "ax.invert_yaxis()\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.set_title('Sum difference in FR per bin')\n",
    "\n",
    "\n",
    "# Plot 6: Scatter plot on top of bars for individual points\n",
    "ax = axs[1, 2]\n",
    "ax.barh(bin_centers, facil_sum, height=bin_size * 0.4, color='#002c94', label='Facilitated')\n",
    "ax.barh(bin_centers, supp_sum, height=bin_size * 0.4, color='#85000c', label='Suppressed')\n",
    "\n",
    "\n",
    "for i in range(len(bin_centers)):\n",
    "    # Adjust index access by removing the '-1' since we already start at 0\n",
    "    facil_points = diff_Sorted_facil_norm[bin_indices_facil == i + 1]\n",
    "    supp_points = diff_Sorted_supp_norm[bin_indices_supp == i + 1]\n",
    "    facil_positions = np.full(facil_points.shape, bin_centers[i])\n",
    "    supp_positions = np.full(supp_points.shape, bin_centers[i])\n",
    "    \n",
    "    # Plot the points; adjust 'alpha' for transparency as needed\n",
    "    ax.scatter(facil_points, facil_positions, color='white', edgecolor = 'black', alpha=0.7, label='Facil. Points' if i == 1 else \"\", s = 10, linewidths=0.5)\n",
    "    ax.scatter(supp_points, supp_positions, color='black', edgecolor = 'black',  alpha=0.7, label='Supp. Points' if i == 1 else \"\", s = 10, linewidths=0.5)\n",
    "\n",
    "ax.set_ylabel('Recording Depth (mm)')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(r'$\\sum \\text{Mean } \\Delta \\text{FR (Hz)}$')\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.set_title(r'$\\sum \\text{Mean } \\Delta \\text{FR (Hz)}$')\n",
    "\n",
    "\n",
    "custom_legends = [Line2D([0], [0], marker='o', color='w', markerfacecolor='white', markeredgecolor='black', label='Facil. Points', markersize=5, linewidth=0),\n",
    "                  Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markeredgecolor='black', label='Supp. Points', markersize=5, linewidth=0)]\n",
    "\n",
    "ax.legend(handles=custom_legends, loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Saving the figure\n",
    "plot_name = \"Diff_resp_depthofprobe_AllPlots_TEST%s.pdf\" % cellType\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name), bbox_inches='tight', dpi=600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "fig.set_size_inches(4,3)\n",
    "ax[0,0].scatter(SparsenessOff_facilitated,SparsenessOn_facilitated, s=.25, c = _new_black)\n",
    "ax[0,0].plot([0,1],[0,1], transform=ax[0,0].transAxes, color='dimgrey', ls = \"--\")\n",
    "# ax.plot([-.35,1.85],[-.35,1.85], transform=ax.transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[0,0].set_title('Sparseness Facilitated')\n",
    "ax[0,0].set_xlabel('Sparseness FR$_{Off}$')\n",
    "ax[0,0].set_ylabel('Sparseness FR$_{On}$')\n",
    "_, ymax = ax[0,0].get_ylim()\n",
    "ax[0,0].set_ylim([0, 1])\n",
    "ax[0,0].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[0,0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "_, xmax = ax[0,0].get_xlim()\n",
    "ax[0,0].set_xlim([0, 1])\n",
    "ax[0,0].xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[0,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[0,0].yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[0,0].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[0,0].tick_params(which='major', color=_new_black)\n",
    "ax[0,0].tick_params(which='minor', color=_new_black)\n",
    "ax[0,0].spines['left'].set_bounds((0, 1))\n",
    "ax[0,0].spines['left'].set_bounds((0,1))\n",
    "ax[0,0].set_box_aspect(1)\n",
    "\n",
    "\n",
    "ax[0,1].scatter(SparsenessOff_suppressed,SparsenessOn_suppressed, s=.25, c = _new_black)\n",
    "ax[0,1].plot([0,1],[0,1], transform=ax[0,1].transAxes, color='dimgrey', ls = \"--\")\n",
    "# ax.plot([-.35,1.85],[-.35,1.85], transform=ax.transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[0,1].set_title('Sparseness Suppressed')\n",
    "ax[0,1].set_xlabel('Sparseness FR$_{Off}$')\n",
    "ax[0,1].set_ylabel('Sparseness FR$_{On}$')\n",
    "_, ymax = ax[0,1].get_ylim()\n",
    "ax[0,1].set_ylim([0, 1])\n",
    "ax[0,1].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[0,1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "_, xmax = ax[0,1].get_xlim()\n",
    "ax[0,1].set_xlim([0, 1])\n",
    "ax[0,1].xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[0,1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[0,1].yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[0,1].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[0,1].tick_params(which='major', color=_new_black)\n",
    "ax[0,1].tick_params(which='minor', color=_new_black)\n",
    "ax[0,1].spines['left'].set_bounds((0, 1))\n",
    "ax[0,1].spines['left'].set_bounds((0,1))\n",
    "ax[0,1].set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "ax[1,0].scatter(Late_SparsenessOff_facilitated, Late_SparsenessOn_facilitated, s=.25, c = _new_black)\n",
    "ax[1,0].plot([0,1],[0,1], transform=ax[1,0].transAxes, color='dimgrey', ls = \"--\")\n",
    "# ax.plot([-.35,1.85],[-.35,1.85], transform=ax.transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[1,0].set_title('Sparseness Facilitated Late')\n",
    "ax[1,0].set_xlabel('Sparseness FR$_{Off}$')\n",
    "ax[1,0].set_ylabel('Sparseness FR$_{On}$')\n",
    "_, ymax = ax[1,0].get_ylim()\n",
    "ax[1,0].set_ylim([0, 1])\n",
    "ax[1,0].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[1,0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "_, xmax = ax[1,0].get_xlim()\n",
    "ax[1,0].set_xlim([0, 1])\n",
    "ax[1,0].xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[1,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[1,0].yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[1,0].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[1,0].tick_params(which='major', color=_new_black)\n",
    "ax[1,0].tick_params(which='minor', color=_new_black)\n",
    "ax[1,0].spines['left'].set_bounds((0, 1))\n",
    "ax[1,0].spines['left'].set_bounds((0,1))\n",
    "ax[1,0].set_box_aspect(1)\n",
    "\n",
    "\n",
    "ax[1,1].scatter(Late_SparsenessOff_suppressed, Late_SparsenessOn_suppressed, s=.25, c =_new_black)\n",
    "ax[1,1].plot([0,1],[0,1], transform=ax[1,1].transAxes, color='dimgrey', ls = \"--\")\n",
    "# ax.plot([-.35,1.85],[-.35,1.85], transform=ax.transAxes, color='dimgrey', ls = \"--\")\n",
    "ax[1,1].set_title('Sparseness Suppressed Late')\n",
    "ax[1,1].set_xlabel('Sparseness FR$_{Off}$')\n",
    "ax[1,1].set_ylabel('Sparseness FR$_{On}$')\n",
    "_, ymax = ax[1,1].get_ylim()\n",
    "ax[1,1].set_ylim([0, 1])\n",
    "ax[1,1].yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[1,1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "_, xmax = ax[1,1].get_xlim()\n",
    "ax[1,1].set_xlim([0, 1])\n",
    "ax[1,1].xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "ax[1,1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[1,1].yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[1,1].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax[1,1].tick_params(which='major', color=_new_black)\n",
    "ax[1,1].tick_params(which='minor', color=_new_black)\n",
    "ax[1,1].spines['left'].set_bounds((0, 1))\n",
    "ax[1,1].spines['left'].set_bounds((0,1))\n",
    "ax[1,1].set_box_aspect(1)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_name = \"Sparseness_AllTimePoints_%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3)  # Create a 2x3 grid of subplots\n",
    "fig.set_size_inches(12, 4)  # Adjust the overall figure size as needed\n",
    "\n",
    "# First row plots\n",
    "plot_data_TC(uniq_Freq, mTCOff_facil, mTCOn_facil, ax=ax[0, 0], title='Early Facilitated Units')\n",
    "plot_data_TC(uniq_Freq, mTCOff_supp, mTCOn_supp, ax=ax[0, 1], title='Early Suppressed Units')\n",
    "plot_data_TC(uniq_Freq, mTCOff, mTCOn, ax=ax[0, 2], title='Early All Units')\n",
    "\n",
    "# Second row plots\n",
    "plot_data_TC(uniq_Freq, Late_mTCOff_facil, Late_mTCOn_facil, ax=ax[1, 0], title='Late Facilitated Units')\n",
    "plot_data_TC(uniq_Freq, Late_mTCOff_supp, Late_mTCOn_supp, ax=ax[1, 1], title='Late Suppressed Units')\n",
    "plot_data_TC(uniq_Freq, Late_mTCOff, Late_mTCOn, ax=ax[1, 2], title='Late All Units')\n",
    "\n",
    "# Assuming the calculation of global_ymin, global_ymax, and yticks as in your previous snippet\n",
    "all_ys = np.hstack([a.get_ylim() for row in ax for a in row])  # Flatten the axes array to iterate\n",
    "global_ymin, global_ymax = np.min(all_ys), np.max(all_ys)\n",
    "tick_spacing = np.ceil((global_ymax - global_ymin) / 5 / 10) * 10\n",
    "yticks = np.arange(np.floor(global_ymin / 10) * 10, np.ceil(global_ymax / 10) * 10 + tick_spacing, step=tick_spacing)\n",
    "\n",
    "# Apply the calculated y-ticks to each subplot\n",
    "for row in ax:\n",
    "    for a in row:\n",
    "        a.set_ylim(global_ymin, global_ymax)\n",
    "        a.set_yticks(yticks)\n",
    "\n",
    "fig.align_ylabels(ax[:, 0])  # Align y labels for the first column\n",
    "fig.align_xlabels(ax[-1, :])  # Align x labels for the last row\n",
    "plt.show()\n",
    "\n",
    "# Saving the figure\n",
    "plot_name = f\"Mean_TCs_Divided_{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name), bbox_inches='tight', dpi=600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(8,3)\n",
    "\n",
    "ax[0].errorbar(octaves, np.nanmean(cFR_facil, axis=1), yerr = stats.sem(cFR_facil, axis=1, nan_policy='omit'),ecolor=_new_black, \\\n",
    "        linestyle='-', c=_new_black, mfc = _new_black, marker='o', markersize = .25,capsize=.5)\n",
    "\n",
    "ax[0].errorbar(octaves, np.nanmean(cFR_On_facil, axis=1), yerr = stats.sem(cFR_On_facil, axis=1, nan_policy='omit'),\\\n",
    "            ecolor='CornflowerBlue', linestyle='-', c='CornflowerBlue', mfc = 'CornflowerBlue', marker='o', markersize = .25, capsize=.5)\n",
    "ax[0].set_xlim(np.round(octaves[0]-0.025,3), np.round(octaves[-1]+0.025,3))\n",
    "ax[0].set_xticks(np.round(octaves,2))\n",
    "ax[0].set_title('Facilitated Neurons')\n",
    "ax[0].set_ylabel('FR (Hz)')\n",
    "ax[0].set_xlabel ('Octaves from Best Frequency')\n",
    "ax[0].legend(['Laser Off','Laser On'])\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].set_yticks(np.floor(ax[0].get_yticks()/10) * 10)\n",
    "ymin0, ymax0 = ax[0].get_ylim()\n",
    "ax[0].set_ylim(0, ymax0)\n",
    "ax[0].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "\n",
    "\n",
    "ax[1].errorbar(octaves, np.nanmean(cFR_supp, axis=1), yerr = stats.sem(cFR_supp, axis=1, nan_policy='omit'),ecolor=_new_black, \\\n",
    "        linestyle='-', c=_new_black, mfc = _new_black, marker='o', markersize = .25, capsize=.5)\n",
    "\n",
    "ax[1].errorbar(octaves, np.nanmean(cFR_On_supp, axis=1), yerr = stats.sem(cFR_On_supp, axis=1, nan_policy='omit'),\\\n",
    "            ecolor='CornflowerBlue', linestyle='-', c='CornflowerBlue', mfc = 'CornflowerBlue', marker='o', markersize = .25, capsize=.5)\n",
    "ax[1].set_xlim(np.round(octaves[0]-0.025,3), np.round(octaves[-1]+0.025,3))\n",
    "ax[1].set_xticks(np.round(octaves,2))\n",
    "ax[1].set_title('Suppressed Neurons')\n",
    "ax[1].set_ylabel('FR (Hz)')\n",
    "ax[1].set_xlabel ('Octaves from Best Frequency')\n",
    "ax[1].legend(['Laser Off','Laser On'])\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].set_yticks(np.floor(ax[1].get_yticks()/10) * 10)\n",
    "ymin1, ymax1 = ax[1].get_ylim()\n",
    "ax[1].set_ylim(0, ymax1)\n",
    "ax[1].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[1].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "\n",
    "\n",
    "ax[2].errorbar(octaves, np.nanmean(cFR, axis=1), yerr = stats.sem(cFR, axis=1, nan_policy='omit'),ecolor=_new_black, \\\n",
    "        linestyle='-', c=_new_black, mfc = _new_black, marker='o', markersize = .25, capsize=.5)\n",
    "\n",
    "ax[2].errorbar(octaves, np.nanmean(cFR_On, axis=1), yerr = stats.sem(cFR_On, axis=1, nan_policy='omit'),\\\n",
    "            ecolor='CornflowerBlue', linestyle='-', c='CornflowerBlue', mfc = 'CornflowerBlue', marker='o', markersize = .25, capsize=.5)\n",
    "ax[2].set_xlim(np.round(octaves[0]-0.025,3), np.round(octaves[-1]+0.025,3))\n",
    "ax[2].set_xticks(np.round(octaves,2))\n",
    "ax[2].set_title('All Neurons')\n",
    "ax[2].set_ylabel('FR (Hz)')\n",
    "ax[2].set_xlabel ('Octaves from Best Frequency')\n",
    "ax[2].legend(['Laser Off','Laser On'])\n",
    "ax[2].spines['right'].set_visible(False)\n",
    "ax[2].spines['top'].set_visible(False)\n",
    "ax[2].set_yticks(np.floor(ax[2].get_yticks()/10) * 10)\n",
    "ymin2, ymax2 = ax[2].get_ylim()\n",
    "ax[2].set_ylim(0, ymax1)\n",
    "ax[2].yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax[2].yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax[2].xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "\n",
    "ax[0].tick_params(which='major', color=_new_black)\n",
    "ax[0].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "ax[1].tick_params(which='major', color=_new_black)\n",
    "ax[1].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "ax[2].tick_params(which='major', color=_new_black)\n",
    "ax[2].tick_params(which='minor', color=_new_black)\n",
    "\n",
    "ax[0].set_box_aspect(.8)\n",
    "ax[1].set_box_aspect(.8)\n",
    "ax[2].set_box_aspect(.8)\n",
    "\n",
    "ax[0].spines['left'].set_bounds((0, ymax0))\n",
    "ax[1].spines['left'].set_bounds((0, ymax1))\n",
    "ax[2].spines['left'].set_bounds((0, ymax2))\n",
    "\n",
    "fig.align_ylabels(ax[:])\n",
    "fig.align_xlabels(ax[:])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_name = \"Centered_TC_divded_%s.pdf\"%cellType\n",
    "# fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(4, 1.5))\n",
    "\n",
    "\n",
    "# Settings for both facilitated and suppressed neurons\n",
    "settings = [\n",
    "    (cFR_facil, cFR_On_facil, errorOff_tc_facil, errorOn_tc_facil, 'Facilitated Neurons', ax[0]),\n",
    "    (cFR_supp, cFR_On_supp, errorOff_tc_supp, errorOn_tc_supp, 'Suppressed Neurons', ax[1])\n",
    "]\n",
    "\n",
    "for current_cFR, current_cFR_On, current_errorOff, current_errorOn, title, axis in settings:\n",
    "    axis.plot(octaves, np.nanmean(current_cFR, axis=1), c=_new_black, linestyle='-')\n",
    "    axis.fill_between(octaves, np.nanmean(current_cFR, axis=1) - current_errorOff, np.nanmean(current_cFR, axis=1) + current_errorOff, alpha=0.5, facecolor=_new_black)\n",
    "    axis.plot(octaves, np.nanmean(current_cFR_On, axis=1), 'CornflowerBlue', linestyle='-')\n",
    "    axis.fill_between(octaves, np.nanmean(current_cFR_On, axis=1) - current_errorOn, np.nanmean(current_cFR_On, axis=1) + current_errorOn, alpha=0.5, facecolor='CornflowerBlue')\n",
    "\n",
    "    axis.set_xlim(np.round(octaves[0]-0.025,3), np.round(octaves[-1]+0.025,3))\n",
    "    axis.set_xticks(np.round(octaves,2))\n",
    "    axis.set_title(title)\n",
    "    axis.set_ylabel('FR (Hz)')\n",
    "    axis.set_xlabel('Octaves from Best Frequency')\n",
    "    axis.legend(['Laser Off','Laser On'])\n",
    "    axis.spines['right'].set_visible(False)\n",
    "    axis.spines['top'].set_visible(False)\n",
    "    axis.set_yticks(np.floor(axis.get_yticks()/10) * 10)\n",
    "    ymin, ymax = axis.get_ylim()\n",
    "    axis.set_ylim(0, ymax)\n",
    "    axis.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "    axis.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "    axis.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "    axis.tick_params(which='major', color=_new_black)\n",
    "    axis.set_box_aspect(.8)\n",
    "    axis.spines['left'].set_bounds((0, ymax))\n",
    "\n",
    "fig.align_ylabels(ax[:])\n",
    "fig.align_xlabels(ax[:])\n",
    "plt.show()\n",
    "\n",
    "plot_name = f\"Centered_TC_divided_Patch_{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(4, 1.5)\n",
    "\n",
    "# Settings for both facilitated and suppressed neurons in the late time period\n",
    "late_settings = [\n",
    "    (Late_cFR_facil, Late_cFR_On_facil, Late_errorOff_tc_facil, Late_errorOn_tc_facil, 'Facilitated NeuronsLate_', ax[0]),\n",
    "    (Late_cFR_supp, Late_cFR_On_supp, Late_errorOff_tc_supp, Late_errorOn_tc_supp, 'Suppressed NeuronsLate_', ax[1])\n",
    "]\n",
    "\n",
    "for Late_current_cFR, Late_current_cFR_On, Late_current_errorOff, Late_current_errorOn, title, axis in late_settings:\n",
    "    axis.plot(octaves, np.nanmean(Late_current_cFR, axis=1), c=_new_black, linestyle='-')\n",
    "    axis.fill_between(octaves, np.nanmean(Late_current_cFR, axis=1) - Late_current_errorOff, np.nanmean(Late_current_cFR, axis=1) + Late_current_errorOff, alpha=0.5, facecolor=_new_black)\n",
    "    axis.plot(octaves, np.nanmean(Late_current_cFR_On, axis=1), 'CornflowerBlue', linestyle='-')\n",
    "    axis.fill_between(octaves, np.nanmean(Late_current_cFR_On, axis=1) - Late_current_errorOn, np.nanmean(Late_current_cFR_On, axis=1) + Late_current_errorOn, alpha=0.5, facecolor='CornflowerBlue')\n",
    "    axis.set_xlim(np.round(octaves[0]-0.025,3), np.round(octaves[-1]+0.025,3))\n",
    "    axis.set_xticks(np.round(octaves,2))\n",
    "    axis.set_title(title)\n",
    "    axis.set_ylabel('FR (Hz)')\n",
    "    axis.set_xlabel('Octaves from Best Frequency')\n",
    "    axis.legend(['Laser Off','Laser On'])\n",
    "    axis.spines['right'].set_visible(False)\n",
    "    axis.spines['top'].set_visible(False)\n",
    "    axis.set_yticks(np.floor(axis.get_yticks()/7) * 10)\n",
    "    ymin, ymax = axis.get_ylim()\n",
    "    axis.set_ylim(0, ymax)\n",
    "    axis.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "    axis.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "    axis.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "    axis.tick_params(which='major', color=_new_black)\n",
    "    axis.set_box_aspect(.8)\n",
    "    axis.spines['left'].set_bounds((0, ymax))\n",
    "\n",
    "# Create custom legend handles\n",
    "legend_elements = [Line2D([0], [0], color=_new_black, lw=4, label='Laser Off'),\n",
    "                   Line2D([0], [0], color='CornflowerBlue', lw=4, label='Laser On'),\n",
    "                   Patch(facecolor=_new_black, edgecolor=_new_black,\n",
    "                         label='Laser Off Confidence', alpha=0.5),\n",
    "                   Patch(facecolor='CornflowerBlue', edgecolor='CornflowerBlue',\n",
    "                         label='Laser On Confidence', alpha=0.5)]\n",
    "\n",
    "# Loop over axes to apply legend modifications\n",
    "for axis in ax:\n",
    "    axis.legend(handles=legend_elements[:2], loc='upper left')  # Adjust as needed\n",
    "fig.align_ylabels(ax[:])\n",
    "fig.align_xlabels(ax[:])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_name = f\"Centered_TC_divided_Patch_LateTimePeriod{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time, plot_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(2,1.5)\n",
    "ax.scatter(BF, depths_numeric, c='seagreen',s=.25)\n",
    "ax.set_box_aspect(1)\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Probe Depth (µm)')\n",
    "ax.set_xscale('log')\n",
    "ax.tick_params(which='major',color=_new_black)\n",
    "ax.tick_params(which='minor', color=_new_black)\n",
    "plt.show()\n",
    "\n",
    "plot_name = \"BF_ProbeDepth_%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))\n",
    "\n",
    "# fig.savefig(os.path.join(fig_dir_time,\"BF_ProbeDepth.pdf\"), bbox_inches='tight', dpi=600, transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from statannotations.Annotator import Annotator\n",
    "\n",
    "data_frames = {\n",
    "    'All': [SparsenessOff_all, SparsenessOn_all],\n",
    "    'Facilitated_Early': [SparsenessOff_facilitated, SparsenessOn_facilitated],\n",
    "    'Suppressed_Early': [SparsenessOff_suppressed, SparsenessOn_suppressed],\n",
    "    'Facilitated_Late': [Late_SparsenessOff_facilitated, Late_SparsenessOn_facilitated],\n",
    "    'Suppressed_Late': [Late_SparsenessOff_suppressed, Late_SparsenessOn_suppressed],\n",
    "\n",
    "}\n",
    "\n",
    "# Create a combined DataFrame\n",
    "df_test = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        'Sparseness': df,\n",
    "        'Condition': 'Off' if i % 2 == 0 else 'On',\n",
    "        'Type': key\n",
    "    }) for key, dfs in data_frames.items() for i, df in enumerate(dfs)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Define custom parameters to remove top and right spines\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "\n",
    "\n",
    "# Define the colors for boxplots\n",
    "colors_facilitated = ['#002c94', 'CornflowerBlue']  # Off, On for facilitated\n",
    "colors_suppressed = ['#85000c', 'CornflowerBlue']  # Off, On for suppressed\n",
    "\n",
    "# Define the categories and their corresponding color maps for boxplots\n",
    "categories = ['Facilitated_Early', 'Facilitated_Late', 'Suppressed_Early', 'Suppressed_Late']\n",
    "color_maps = {\n",
    "    'Facilitated_Early': colors_facilitated,\n",
    "    'Facilitated_Late': colors_facilitated,\n",
    "    'Suppressed_Early': colors_suppressed,\n",
    "    'Suppressed_Late': colors_suppressed\n",
    "}\n",
    "\n",
    "# Prepare the plot\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(5, 10), sharey=True)  # Adjusted figsize\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each category to plot\n",
    "for idx, category in enumerate(categories):\n",
    "    ax = axes[idx]\n",
    "    subset = df_test[df_test['Type'] == category]\n",
    "    \n",
    "    # Boxplot\n",
    "    sns.boxplot(data=subset, x='Type', y='Sparseness', hue='Condition',\n",
    "                palette=color_maps[category], ax=ax, zorder=1)\n",
    "    \n",
    "    # Stripplot with 'dimgrey' color using palette\n",
    "    sns.stripplot(data=subset, x='Type', y='Sparseness', hue='Condition', dodge=True,\n",
    "                  palette=[_new_black, _new_black], ax=ax, alpha=0.60, jitter=True, edgecolor='gray', linewidth=0.5, zorder=2)\n",
    "\n",
    "    # Customize legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if idx == 0:\n",
    "        ax.legend(handles[:2], ['Off', 'On'], title='Condition')\n",
    "    else:\n",
    "        ax.legend([], [], frameon=False)\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(category)\n",
    "\n",
    "# Adjust labels and layout\n",
    "plt.tight_layout(pad=3.0)  # Adjusted padding for layout\n",
    "plt.show()\n",
    "\n",
    "plot_name = f\"Sparseness_divided_{cellType}.pdf\"\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function for each condition\n",
    "t2pOff, t2pOn = find_time_to_peak(peakCellstuseOff, peakCellstuseOn, early_evoked_Ind, spontInd)\n",
    "t2pOff_facil, t2pOn_facil = find_time_to_peak(peakCellstuseOff_facil, peakCellstuseOn_facil, early_evoked_Ind, spontInd)\n",
    "t2pOff_supp, t2pOn_supp = find_time_to_peak(peakCellstuseOff_supp, peakCellstuseOn_supp, early_evoked_Ind, spontInd)\n",
    "\n",
    "\n",
    "# Creating separate dataframes and adding a new 'Condition' column\n",
    "df_facil_off = pd.DataFrame({'Time': [time * 1000 for time in t2pOff_facil], 'Condition': 'Facilitated Off'})\n",
    "df_facil_on = pd.DataFrame({'Time': [time * 1000 for time in t2pOn_facil], 'Condition': 'Facilitated On'})\n",
    "df_supp_off = pd.DataFrame({'Time': [time * 1000 for time in t2pOff_supp], 'Condition': 'Suppressed Off'})\n",
    "df_supp_on = pd.DataFrame({'Time': [time * 1000 for time in t2pOn_supp], 'Condition': 'Suppressed On'})\n",
    "\n",
    "# Concatenating dataframes by group\n",
    "df_facilitated = pd.concat([df_facil_off, df_facil_on], ignore_index=True)\n",
    "df_suppressed = pd.concat([df_supp_off, df_supp_on], ignore_index=True)\n",
    "\n",
    "# Define the colors for boxplots\n",
    "colors_facilitated = ['#002c94', 'CornflowerBlue']  # Off, On for facilitated\n",
    "colors_suppressed = ['#85000c', 'CornflowerBlue']  # Off, On for suppressed\n",
    "\n",
    "# Plotting for Facilitated Conditions\n",
    "fig_facil, ax_facil = plt.subplots(figsize=(2.5, 5))\n",
    "sns.boxplot(x='Condition', y='Time', data=df_facilitated, palette=colors_facilitated, \n",
    "            medianprops={'color': _new_black, 'linewidth': 2}, width=0.5)\n",
    "sns.stripplot(x='Condition', y='Time', data=df_facilitated, color=_new_black, size=4, jitter=True, alpha=0.8)\n",
    "ax_facil.set_title('Time to Peak for Facilitated Conditions')\n",
    "ax_facil.set_ylabel('Time to Peak (ms)')\n",
    "ax_facil.set_xlabel('Condition')\n",
    "\n",
    "# Save the Facilitated plot\n",
    "plot_name_facil = f\"Time2Peak_Facilitated_{cellType}.pdf\"\n",
    "fig_facil.savefig(os.path.join(fig_dir_time, plot_name_facil))\n",
    "\n",
    "# Plotting for Suppressed Conditions\n",
    "fig_supp, ax_supp = plt.subplots(figsize=(2.5, 5))\n",
    "sns.boxplot(x='Condition', y='Time', data=df_suppressed, palette=colors_suppressed, \n",
    "            medianprops={'color': _new_black, 'linewidth': 2}, width=0.5)\n",
    "sns.stripplot(x='Condition', y='Time', data=df_suppressed, color=_new_black, size=4, jitter=True, alpha=0.8)\n",
    "ax_supp.set_title('Time to Peak for Suppressed Conditions')\n",
    "ax_supp.set_ylabel('Time to Peak (ms)')\n",
    "ax_supp.set_xlabel('Condition')\n",
    "\n",
    "# Save the Suppressed plot\n",
    "plot_name_supp = f\"Time2Peak_Suppressed_{cellType}.pdf\"\n",
    "fig_supp.savefig(os.path.join(fig_dir_time, plot_name_supp))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual cell psth's, tuning curves, and raster plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the mean PSTH for both LaserOn and LaserOff conditions for each cell. Optional: plot individual PSTH's by changing show_plots = TRUE.\n",
    "_, _ = plot_cells_psth(\n",
    "    meanLaserOff, \n",
    "    meanLaserOn, \n",
    "    time, \n",
    "    laserStart, \n",
    "    tStart, \n",
    "    tDur, \n",
    "    None, \n",
    "    None, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_,_ = plot_cells_psth(\n",
    "    meanLaserOff_masked, \n",
    "    meanLaserOn_masked, \n",
    "    time, \n",
    "    laserStart, \n",
    "    tStart, \n",
    "    tDur, \n",
    "    None,\n",
    "    None, \n",
    "    PSTH_Laser_norm_masked, \n",
    "    laserOnlyDur, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_individual_mean_tuning_curves(mTCOff, mTCOn, uniq_Freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = plot_cells_psth(\n",
    "    facilitated_cells_Off, \n",
    "    facilitated_cells_On, \n",
    "    time, \n",
    "    laserStart, \n",
    "    tStart, \n",
    "    tDur, \n",
    "    None,\n",
    "    None, \n",
    "    None, \n",
    "    laserOnlyDur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = plot_cells_psth(\n",
    "    suppressed_cells_Off, \n",
    "    suppressed_cells_On, \n",
    "    time, \n",
    "    laserStart, \n",
    "    tStart, \n",
    "    tDur, \n",
    "    None,\n",
    "    None, \n",
    "    None, \n",
    "    laserOnlyDur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centered_individual_tuning_curves(cFR_facil, cFR_On_facil, octaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_centered_individual_tuning_curves(cFR_supp, cFR_On_supp, octaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Example Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psthTC_facil = psthTC[:,:,facilitated_Ind]\n",
    "psthTC_On_facil = psthTC_On[:,:,facilitated_Ind]\n",
    "\n",
    "psthTC_suppressed = psthTC[:,:,suppressed_Ind]\n",
    "psthTC_On_suppressed = psthTC_On[:,:,suppressed_Ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT EXAMPLE CELLS FACILITATED\n",
    "# cellID = 69 #PV\n",
    "cellID = 6 #SOM\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(2, 4)\n",
    "fig.set_size_inches(6,3)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.plot(uniq_Freq, mTCOff_facil[:,cellID], c=_new_black)\n",
    "ax.plot(uniq_Freq, mTCOn_facil[:,cellID], 'CornflowerBlue')\n",
    "ax.set_xscale('log')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# ax.set_box_aspect(1)\n",
    "# ax[1,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax.set_title('Facil Frequency Response Cell = %i'%cellID)\n",
    "ax.set_ylabel('FR (Hz)')\n",
    "ax.set_xlabel ('Frequency (Hz)')\n",
    "ax.legend(['Laser Off','Laser On'])\n",
    "ymin0, ymax0 = ax.get_ylim()\n",
    "ax.set_ylim([0, ymax0])\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax.tick_params(which='major', color=_new_black)\n",
    "ax.tick_params(which='minor', color=_new_black)\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 1], sharey=ax, sharex=ax)\n",
    "plt.setp(ax1.get_yticklabels(), visible=False)\n",
    "ax1.plot(uniq_Freq, Late_mTCOff_facil[:,cellID], c=_new_black)\n",
    "ax1.plot(uniq_Freq, Late_mTCOn_facil[:,cellID], 'CornflowerBlue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "# ax.set_box_aspect(1)\n",
    "# ax[1,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax1.set_title('Facil Frequency Response Cell = %i'%cellID)\n",
    "# ax1.set_ylabel('FR (Hz)')\n",
    "ax1.set_xlabel ('Frequency (Hz)')\n",
    "ax1.legend(['Laser Off','Laser On'])\n",
    "ymin1, ymax1 = ax1.get_ylim()\n",
    "ax1.set_ylim([0, ymax1])\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax1.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax1.tick_params(which='major', color=_new_black)\n",
    "ax1.tick_params(which='minor', color=_new_black)\n",
    "ax1.set_box_aspect(1)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, :-2])\n",
    "ax2.plot(time,facilitated_cells_Off[:,cellID], c=_new_black)\n",
    "ax2.plot(time,facilitated_cells_On[:,cellID], c='CornflowerBlue')\n",
    "ax2.axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax2.axvline(x=tDur,ls='--', c=_new_black)\n",
    "ax2.legend(['Laser Off','Laser On'])\n",
    "ax2.set(xlabel = 'Time (s)')\n",
    "ax2.set(ylabel ='FR (Hz)')\n",
    "ax2.set_title('PSTH for Cell ID = %i' %cellID)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.set_yticks(np.ceil(ax2.get_yticks()/10) * 10)\n",
    "ymin2, ymax2 = ax2.get_ylim()\n",
    "ax2.set_ylim(0, ymax2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax2.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax2.set_xlim(np.min(time), np.max(time))\n",
    "ax2.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax2.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax2.tick_params(which='major', color=_new_black)\n",
    "ax2.tick_params(which='minor', color=_new_black)\n",
    "# ax2.set_box_aspect(.6)\n",
    "\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0:, 2])\n",
    "for uniq in range(len(uniq_Freq)):\n",
    "    ax3.plot(time,psthTC_facil[uniq,:,cellID]+250*uniq, c=_new_black)\n",
    "    ax3.plot(time,psthTC_On_facil[uniq,:,cellID]+250*uniq, 'CornflowerBlue')\n",
    "    ax3.set_box_aspect(2)\n",
    "    \n",
    "ax3.axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax3.axvline(x=tDur,ls='--', c=_new_black)\n",
    "ymin3, ymax3 = ax3.get_ylim()\n",
    "ax3.set_ylim(0, ymax3)\n",
    "ax3.yaxis.set_major_locator(ticker.LinearLocator(numticks=20))\n",
    "ax3.set_yticklabels(ticker.FormatStrFormatter('%d').format_ticks(np.ceil(uniq_Freq/1000)));\n",
    "\n",
    "\n",
    "ax3.set_xlim(np.min(time), np.max(time))\n",
    "ax3.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax3.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax3.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax3.tick_params(which='major', color=_new_black)\n",
    "ax3.tick_params(which='minor', color=_new_black)\n",
    "ax3.set_xlabel ('Time(s)')\n",
    "ax3.set_ylabel ('Frequency (kHz)')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[0:, 3])\n",
    "\n",
    "cmap = cmr.get_sub_cmap(\"cmr.tropical\", 0.1, 1, N=len(uniq_Freq));\n",
    "\n",
    "\n",
    "c_IND = (np.ceil(Facil_SpikeSortI_toneResp[cellID]/20)*20)\n",
    "spikesortind_c_off = np.where(Facil_SpikeSortI_toneResp[cellID] <= np.max(c_IND/2))\n",
    "spikesortind_c_on = np.where(Facil_SpikeSortI_toneResp[cellID] > np.max(c_IND/2))\n",
    "\n",
    "spikesortid_off = Facil_SpikeSortI_toneResp[cellID][spikesortind_c_off]\n",
    "spikesortid_on = Facil_SpikeSortI_toneResp[cellID][spikesortind_c_on]\n",
    "\n",
    "rastoff = np.asarray(Facil_Rasters_toneResp[cellID])[spikesortind_c_off]\n",
    "raston= np.asarray(Facil_Rasters_toneResp[cellID])[spikesortind_c_on]\n",
    "\n",
    "\n",
    "\n",
    "pp1 = plt.Rectangle((tStart, len(trialOrder)/2),\n",
    "                laserDur, len(trialOrder)/2, alpha= 0.1)\n",
    "pp2 = plt.Rectangle((tStart, tStart),\n",
    "                tDur, len(trialOrder)/2, facecolor=_new_black, alpha= 0.1)\n",
    "ax4.add_patch(pp1)\n",
    "ax4.add_patch(pp2)\n",
    "#     ax[0].plot(Rasters,spikeSortI,'ko',markersize=2.3)\n",
    "cax = ax4.scatter(rastoff,spikesortid_off,.25,c=spikesortid_off,cmap=cmap, marker='|', linewidth=.5)\n",
    "\n",
    "cax2 = ax4.scatter(raston,spikesortid_on,.25,c=spikesortid_on,cmap=cmap, marker='|', linewidth=.5)\n",
    "\n",
    "cbar = fig.colorbar(cax, shrink=.4)\n",
    "#     cbar.ax.ticker.LinearLocator(numticks=None, presets=None)\n",
    "cbar.ax.yaxis.set_major_locator(ticker.LinearLocator(19))\n",
    "#     cbar.ax.locator_params(axis = 'y', nbins=20)\n",
    "# cbar.set_ticks(uniq_Freq/1000)\n",
    "cbar.ax.set_yticklabels(ticker.FormatStrFormatter('%d').format_ticks(np.ceil(uniq_Freq/1000)),fontsize=4);\n",
    "cbar.set_label('Frequency(kHz)');\n",
    "\n",
    "#     ax[0].scatter(Rasters,spikeSortI,2,'k','o')\n",
    "ax4.set_xlabel ('Time(s)')\n",
    "ax4.set_ylabel ('Trials')\n",
    "ax4.set_title('Raster Plot for Cell ID = %i' %cellID)\n",
    "ax4.tick_params(axis='x')\n",
    "ax4.tick_params(axis='y')\n",
    "ax4.locator_params(axis = 'y', nbins=5)\n",
    "ax4.locator_params(axis = 'x', nbins=8)\n",
    "ax4.set_ylim([0, len(trialOrder)])\n",
    "ax4.yaxis.set_major_locator(ticker.LinearLocator(3))\n",
    "ax4.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax4.set_xlim(np.min(time), np.max(time))\n",
    "ax4.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax4.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax4.tick_params(which='major', color=_new_black)\n",
    "ax4.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "# fig.align_labels(cbar.ax)\n",
    "ax4.set_box_aspect(2)\n",
    "\n",
    "\n",
    "# ax[0].spines.bottom.set_bounds(x.min(), x.max())\n",
    "ax.spines['left'].set_bounds((0, ymax0))\n",
    "ax1.spines['left'].set_bounds((0, ymax1))\n",
    "ax2.spines['left'].set_bounds((0, ymax2))\n",
    "\n",
    "# fig.align_ylabels(ax[:])\n",
    "# fig.align_xlabels(ax[:])\n",
    "\n",
    "\n",
    "plot_name = \"Example_Cell_Facil%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT EXAMPLE CELLS SUPPRESSED\n",
    "# cellID_supp = 53 #PV\n",
    "cellID_supp = 204 #som\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(2, 4)\n",
    "fig.set_size_inches(6,3)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.plot(uniq_Freq, mTCOff_supp[:,cellID_supp], c=_new_black)\n",
    "ax.plot(uniq_Freq, mTCOn_supp[:,cellID_supp], 'CornflowerBlue')\n",
    "ax.set_xscale('log')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# ax.set_box_aspect(1)\n",
    "# ax[1,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax.set_title('Facil Frequency Response Cell = %i'%cellID_supp)\n",
    "ax.set_ylabel('FR (Hz)')\n",
    "ax.set_xlabel ('Frequency (Hz)')\n",
    "ax.legend(['Laser Off','Laser On'])\n",
    "ymin0, ymax0 = ax.get_ylim()\n",
    "ax.set_ylim([0, ymax0])\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax.tick_params(which='major', color=_new_black)\n",
    "ax.tick_params(which='minor', color=_new_black)\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 1], sharey=ax, sharex=ax)\n",
    "plt.setp(ax1.get_yticklabels(), visible=False)\n",
    "ax1.plot(uniq_Freq, Late_mTCOff_supp[:,cellID_supp], c=_new_black)\n",
    "ax1.plot(uniq_Freq, Late_mTCOn_supp[:,cellID_supp], 'CornflowerBlue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "# ax.set_box_aspect(1)\n",
    "# ax[1,0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax1.set_title('Facil Frequency Response Cell = %i'%cellID_supp)\n",
    "# ax1.set_ylabel('FR (Hz)')\n",
    "ax1.set_xlabel ('Frequency (Hz)')\n",
    "ax1.legend(['Laser Off','Laser On'])\n",
    "ymin1, ymax1 = ax1.get_ylim()\n",
    "ax1.set_ylim([0, ymax1])\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax1.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax1.tick_params(which='major', color=_new_black)\n",
    "ax1.tick_params(which='minor', color=_new_black)\n",
    "ax1.set_box_aspect(1)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, :-2])\n",
    "ax2.plot(time,suppressed_cells_Off[:,cellID_supp], c=_new_black)\n",
    "ax2.plot(time,suppressed_cells_On[:,cellID_supp], c='CornflowerBlue')\n",
    "ax2.axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax2.axvline(x=tDur,ls='--', c=_new_black)\n",
    "ax2.legend(['Laser Off','Laser On'])\n",
    "ax2.set(xlabel = 'Time (s)')\n",
    "ax2.set(ylabel ='FR (Hz)')\n",
    "ax2.set_title('PSTH for Cell ID = %i' %cellID_supp)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.set_yticks(np.ceil(ax2.get_yticks()/10) * 10)\n",
    "ymin2, ymax2 = ax2.get_ylim()\n",
    "ax2.set_ylim(0, ymax2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "ax2.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "ax2.set_xlim(np.min(time), np.max(time))\n",
    "ax2.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax2.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax2.tick_params(which='major', color=_new_black)\n",
    "ax2.tick_params(which='minor', color=_new_black)\n",
    "# ax2.set_box_aspect(.8)\n",
    "\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0:, 2])\n",
    "for uniq in range(len(uniq_Freq)):\n",
    "    ax3.plot(time,psthTC_suppressed[uniq,:,cellID_supp]+250*uniq, c=_new_black)\n",
    "    ax3.plot(time,psthTC_On_suppressed[uniq,:,cellID_supp]+250*uniq, 'CornflowerBlue')\n",
    "    ax3.set_box_aspect(2)\n",
    "    \n",
    "ax3.axvline(x=tStart,ls='--', c=_new_black)\n",
    "ax3.axvline(x=tDur,ls='--', c=_new_black)\n",
    "ymin3, ymax3 = ax3.get_ylim()\n",
    "ax3.set_ylim(0, ymax3)\n",
    "ax3.yaxis.set_major_locator(ticker.LinearLocator(numticks=20))\n",
    "ax3.set_yticklabels(ticker.FormatStrFormatter('%d').format_ticks(np.ceil(uniq_Freq/1000)));\n",
    "# ax3.set_yticklabels(np.ceil(uniq_Freq/1000));\n",
    "\n",
    "\n",
    "ax3.set_xlim(np.min(time), np.max(time))\n",
    "ax3.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax3.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "ax3.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax3.tick_params(which='major', color=_new_black)\n",
    "ax3.tick_params(which='minor', color=_new_black)\n",
    "ax3.set_xlabel ('Time(s)')\n",
    "ax3.set_ylabel ('Frequency (kHz)')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[0:, 3])\n",
    "\n",
    "c_IND = (np.ceil(Supp_SpikeSortI_toneResp[cellID_supp]/20)*20)\n",
    "spikesortind_c_off = np.where(Supp_SpikeSortI_toneResp[cellID_supp] <= np.max(c_IND/2))\n",
    "spikesortind_c_on = np.where(Supp_SpikeSortI_toneResp[cellID_supp] > np.max(c_IND/2))\n",
    "\n",
    "spikesortid_off = Supp_SpikeSortI_toneResp[cellID_supp][spikesortind_c_off]\n",
    "spikesortid_on = Supp_SpikeSortI_toneResp[cellID_supp][spikesortind_c_on]\n",
    "\n",
    "rastoff = np.asarray(Supp_Rasters_toneResp[cellID_supp])[spikesortind_c_off]\n",
    "raston= np.asarray(Supp_Rasters_toneResp[cellID_supp])[spikesortind_c_on]\n",
    "\n",
    "\n",
    "\n",
    "pp1 = plt.Rectangle((tStart, len(trialOrder)/2),\n",
    "                laserDur, len(trialOrder)/2, alpha= 0.1)\n",
    "pp2 = plt.Rectangle((tStart, tStart),\n",
    "                tDur, len(trialOrder)/2, facecolor=_new_black, alpha= 0.1)\n",
    "ax4.add_patch(pp1)\n",
    "ax4.add_patch(pp2)\n",
    "#     ax[0].plot(Rasters,spikeSortI,'ko',markersize=2.3)\n",
    "cax = ax4.scatter(rastoff,spikesortid_off,.25,c=spikesortid_off,cmap=cmap, marker='|', linewidth=.5)\n",
    "cax2 = ax4.scatter(raston,spikesortid_on,.25,c=spikesortid_on,cmap=cmap, marker='|', linewidth=.5)\n",
    "\n",
    "cbar = fig.colorbar(cax, shrink=.4)\n",
    "#     cbar.ax.ticker.LinearLocator(numticks=None, presets=None)\n",
    "cbar.ax.yaxis.set_major_locator(ticker.LinearLocator(19))\n",
    "#     cbar.ax.locator_params(axis = 'y', nbins=20)\n",
    "# cbar.set_ticks(uniq_Freq/1000)\n",
    "cbar.ax.set_yticklabels(ticker.FormatStrFormatter('%d').format_ticks(np.ceil(uniq_Freq/1000)),fontsize=4);\n",
    "cbar.set_label('Frequency(kHz)');\n",
    "\n",
    "#     ax[0].scatter(Rasters,spikeSortI,2,'k','o')\n",
    "ax4.set_xlabel ('Time(s)')\n",
    "ax4.set_ylabel ('Trials')\n",
    "ax4.set_title('Raster Plot for Cell ID = %i' %cellID_supp)\n",
    "ax4.tick_params(axis='x')\n",
    "ax4.tick_params(axis='y')\n",
    "ax4.locator_params(axis = 'y', nbins=5)\n",
    "ax4.locator_params(axis = 'x', nbins=8)\n",
    "ax4.set_ylim([0, len(trialOrder)])\n",
    "ax4.yaxis.set_major_locator(ticker.LinearLocator(3))\n",
    "ax4.yaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "ax4.set_xlim(np.min(time), np.max(time))\n",
    "ax4.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax4.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.2g'))\n",
    "ax4.tick_params(which='major', color=_new_black)\n",
    "ax4.tick_params(which='minor', color=_new_black)\n",
    "\n",
    "\n",
    "# fig.align_labels(cbar.ax)\n",
    "ax4.set_box_aspect(2)\n",
    "\n",
    "\n",
    "# ax[0].spines.bottom.set_bounds(x.min(), x.max())\n",
    "ax.spines['left'].set_bounds((0, ymax0))\n",
    "ax1.spines['left'].set_bounds((0, ymax1))\n",
    "ax2.spines['left'].set_bounds((0, ymax2))\n",
    "\n",
    "# fig.align_ylabels(ax[:])\n",
    "# fig.align_xlabels(ax[:])\n",
    "\n",
    "\n",
    "plot_name = \"Example_Cell_Suppressed%s.pdf\"%cellType\n",
    "fig.savefig(os.path.join(fig_dir_time,plot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create initial DataFrame and populate it\n",
    "def create_stats_df(data_off, data_on, indices):\n",
    "    stats_df = pd.DataFrame()\n",
    "    for period, index in indices.items():\n",
    "        stats_df[f'Mean FR Off {period.capitalize()}'] = pd.Series(data_off[index, :].mean(axis=0))\n",
    "        stats_df[f'Mean FR On {period.capitalize()}'] = pd.Series(data_on[index, :].mean(axis=0))\n",
    "    return stats_df\n",
    "\n",
    "def describe_and_enhance(stats_df):\n",
    "    described = stats_df.describe()\n",
    "    confidence_level = 0.95\n",
    "\n",
    "    for column in stats_df.columns:\n",
    "        if stats_df[column].dtype.kind in 'bifc':  # Check if the column is numeric\n",
    "            if len(stats_df[column]) > 1:  # Check if there are at least 2 data points\n",
    "                try:\n",
    "                    # Computing median\n",
    "                    median_val = stats_df[column].median()\n",
    "                    described.loc['median', column] = median_val\n",
    "\n",
    "                    # Computing mean and SEM for confidence interval\n",
    "                    mean_val = stats_df[column].mean()\n",
    "                    sem_val = stats_df[column].sem()\n",
    "                    ci_low, ci_high = stats.t.interval(confidence_level, len(stats_df[column])-1, loc=mean_val, scale=sem_val)\n",
    "                    \n",
    "                    margin_of_error = ci_high - mean_val  # This is the margin of error\n",
    "\n",
    "                    described.loc['mean', column] = mean_val  # Just to ensure the mean is explicitly set in the described DataFrame\n",
    "                    described.loc['SEM', column] = sem_val  # Adding the SEM value explicitly\n",
    "                    described.loc['CI_low', column] = ci_low  # Lower bound of the CI\n",
    "                    described.loc['CI_high', column] = ci_high  # Upper bound of the CI\n",
    "                    described.loc['MOE', column] = margin_of_error  # Adding the margin of error\n",
    "                    described.loc['IQR', column] = described.loc['75%', column] - described.loc['25%', column]  # Interquartile range\n",
    "                except Exception as e:\n",
    "                    print(f\"Error computing for column {column}: {e}\")\n",
    "            else:\n",
    "                print(f\"Not enough data to compute statistics for column {column}\")\n",
    "        else:\n",
    "            print(f\"Column {column} is not numeric and will be skipped.\")\n",
    "\n",
    "    return described\n",
    "\n",
    "\n",
    "# Statistical testing function\n",
    "def perform_analysis(df, col1, col2):\n",
    "    stat, p = stats.wilcoxon(df[col1], df[col2])\n",
    "    n = df[col1].notna().sum()  # Assuming NaN handling required, adjust as necessary\n",
    "    z = (stat - n*(n+1)/4) / np.sqrt(n*(n+1)*(2*n+1)/24)\n",
    "    r = abs(z / np.sqrt(n))\n",
    "    return stat, p, z, r\n",
    "\n",
    "\n",
    "def create_and_describe_df(data, columns):\n",
    "    df = pd.DataFrame(data.T, columns=columns)  # Creating DataFrame and transposing data if necessary\n",
    "    described = df.describe()  # Get basic descriptive statistics\n",
    "    \n",
    "    # Calculate the median and add it to the described DataFrame\n",
    "    median_values = df.median()\n",
    "    for column in columns:\n",
    "        if df[column].dtype.kind in 'bifc':  # Check if the column is numeric\n",
    "            described.loc['median', column] = median_values[column]\n",
    "            \n",
    "            confidence_level = 0.95  # 95% confidence\n",
    "            if len(df[column].dropna()) > 1:  # Check if there are at least 2 data points after dropping NaN\n",
    "                mean_val = described.loc['mean', column]\n",
    "                sem_val = stats.sem(df[column], nan_policy='omit')  # Calculate the SEM, handling NaN values\n",
    "                ci_low, ci_high = stats.t.interval(confidence_level, len(df[column].dropna())-1, loc=mean_val, scale=sem_val)\n",
    "                \n",
    "                margin_of_error = ci_high - mean_val  # This is the margin of error\n",
    "\n",
    "                described.loc['SEM', column] = sem_val  # Adding the SEM value explicitly\n",
    "                described.loc['CI_low', column] = ci_low  # Lower bound of the CI\n",
    "                described.loc['CI_high', column] = ci_high  # Upper bound of the CI\n",
    "                described.loc['MOE', column] = margin_of_error  # Adding the margin of error\n",
    "                described.loc['IQR', column] = described.loc['75%', column] - described.loc['25%', column]  # Calculate IQR\n",
    "            else:\n",
    "                print(f\"Not enough data to compute statistics for column {column}\")\n",
    "        else:\n",
    "            print(f\"Column {column} is not numeric and will be skipped.\")\n",
    "\n",
    "    return df, described\n",
    "\n",
    "# Performing statistical analysis on octaves\n",
    "def perform_analysis_octaves(off_data, on_data):\n",
    "    try:\n",
    "        stat, p = stats.wilcoxon(off_data, on_data, nan_policy='omit')\n",
    "        n = np.count_nonzero(~np.isnan(off_data) & ~np.isnan(on_data))\n",
    "        z = (stat - n*(n+1)/4) / np.sqrt(n*(n+1)*(2*n+1)/24)\n",
    "        r = abs(z / np.sqrt(n))\n",
    "        return {\"Test Statistic\": stat, \"p Value\": p, \"Z Value\": z, \"Effect Size\": r}\n",
    "    except ValueError as e:\n",
    "        return {\"Test Statistic\": np.nan, \"p Value\": np.nan, \"Z Value\": np.nan, \"Effect Size\": np.nan}\n",
    "\n",
    "\n",
    "def save_dataframes(dfs, base_directory, base_filename):\n",
    "    for key, df in dfs.items():\n",
    "        # Construct the full path for the Excel file\n",
    "        excel_path = os.path.join(base_directory, f\"{base_filename}_{key}.xlsx\")\n",
    "        # Save DataFrame to Excel\n",
    "        df.to_excel(excel_path, index=True)\n",
    "        \n",
    "        # Construct the full path for the CSV file\n",
    "        csv_path = os.path.join(base_directory, f\"{base_filename}_{key}.csv\")\n",
    "        # Save DataFrame to CSV\n",
    "        df.to_csv(csv_path, index=True)\n",
    "\n",
    "\n",
    "def pad_and_create_dataframe(data_lists, columns):\n",
    "    # Find the maximum length among all lists and pad them\n",
    "    max_length = max(len(lst) for lst in data_lists)\n",
    "    padded_data = [lst + [np.nan] * (max_length - len(lst)) for lst in data_lists]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    return pd.DataFrame(dict(zip(columns, padded_data)), index=[f'Spar{i}' for i in range(1, max_length + 1)])\n",
    "\n",
    "def calculate_statistics(df):\n",
    "    described = df.describe()\n",
    "    \n",
    "    # Explicitly calculate and add Median if not present\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype.kind in 'bifc':  # Check if the column is numeric\n",
    "            median_val = df[column].median()\n",
    "            described.loc['Median', column] = median_val  # Add Median to the described DataFrame\n",
    "\n",
    "            # Continue with additional statistics\n",
    "            n = len(df[column].dropna())  # Number of non-NA values\n",
    "            if n > 1:\n",
    "                mean_val = described.loc['mean', column]\n",
    "                sem_val = df[column].sem()\n",
    "                ci_low, ci_high = stats.t.interval(0.95, n-1, loc=mean_val, scale=sem_val)\n",
    "                margin_of_error = ci_high - mean_val\n",
    "\n",
    "                described.loc['SEM', column] = sem_val\n",
    "                described.loc['CI_low', column] = ci_low\n",
    "                described.loc['CI_high', column] = ci_high\n",
    "                described.loc['MOE', column] = margin_of_error\n",
    "                described.loc['IQR', column] = described.loc['75%', column] - described.loc['25%', column]\n",
    "            else:\n",
    "                print(f\"Not enough data to compute full statistics for column {column}\")\n",
    "        else:\n",
    "            print(f\"Column {column} is not numeric and will be skipped.\")\n",
    "\n",
    "    return described    \n",
    "def perform_statistical_analysis(df, pairs):\n",
    "    results = {}\n",
    "    for label, (col1, col2) in pairs.items():\n",
    "        off_data = df[col1]\n",
    "        on_data = df[col2]\n",
    "        try:\n",
    "            stat, p = stats.wilcoxon(off_data, on_data, nan_policy='omit')\n",
    "            n = np.count_nonzero(~np.isnan(off_data) & ~np.isnan(on_data))\n",
    "            z = (stat - n*(n+1)/4) / np.sqrt(n*(n+1)*(2*n+1)/24)\n",
    "            r = abs(z / np.sqrt(n))\n",
    "            results[label] = {\"Test Statistic\": stat, \"p Value\": p, \"Z Value\": z, \"Effect Size\": r}\n",
    "        except ValueError:\n",
    "            results[label] = {\"Test Statistic\": np.nan, \"p Value\": np.nan, \"Z Value\": np.nan, \"Effect Size\": np.nan}\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming toneRespPSTH.shape returns something like (time, trials, n_cells)\n",
    "_, _, n_cells = toneRespPSTH.shape\n",
    "\n",
    "# Convert number of cells to string for writing\n",
    "n_cells_str = str(n_cells)\n",
    "\n",
    "# Prepare file name and path\n",
    "cellnum_type = f\"N_allCells_{cellType}.txt\"\n",
    "cellnum_path = os.path.join(fig_dir_time, cellnum_type)\n",
    "\n",
    "# Using with statement for better file handling\n",
    "with open(cellnum_path, 'w') as cellnum_file:\n",
    "    cellnum_file.write(f'Number of Significant Units: {n_cells_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_path = os.path.join(dataLoc,'{0}_Recordings/{1}/{2}'.format(cellType, Virus, data_paper))\n",
    "\n",
    "from datetime import datetime\n",
    "date = datetime.now().strftime('%d%m%Y')\n",
    "date_time = datetime.now().strftime('%d%m%Y%I%M%p')\n",
    "stats_folder = 'Statistics_{}'.format(cellType)\n",
    "stats_folder_name = 'Statistics_AllCells_{0}'.format(date)\n",
    "stats_folder_name_detailed = 'Statistics_AllCells_{0}_{1}'.format(date_time, main_stim_file)\n",
    "stats_dir = os.path.join(stats_path, stats_folder, stats_folder_name)\n",
    "stats_dir_time = os.path.join(stats_path, stats_folder, stats_folder_name,stats_folder_name_detailed)\n",
    "\n",
    "\n",
    "if not os.path.exists(stats_dir):\n",
    "    os.makedirs(stats_dir)\n",
    "    os.makedirs(stats_dir_time)\n",
    "else:\n",
    "    os.makedirs(stats_dir_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <center> Firing Rates </center> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "############################## Figure 3 & 4 ##############################\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "# Define indices and data sources once for consistency and reusability\n",
    "indices = {\n",
    "    'early': early_evoked_Ind,\n",
    "    'late': late_evoked_Ind,\n",
    "    'spont': spontInd\n",
    "}\n",
    "\n",
    "data_sources = {\n",
    "    'All': (meanLaserOff_masked, meanLaserOn_masked),\n",
    "    'Facilitated': (facilitated_cells_Off, facilitated_cells_On),\n",
    "    'Suppressed': (suppressed_cells_Off, suppressed_cells_On),\n",
    "    'Spontaneous': (meanLaserOff_masked, meanLaserOn_masked)  # Assuming same source for simplicity\n",
    "}\n",
    "\n",
    "\n",
    "# Create all DataFrames\n",
    "stats_dfs = {key: create_stats_df(off, on, indices) for key, (off, on) in data_sources.items()}\n",
    "\n",
    "\n",
    "# Describe and enhance all DataFrames\n",
    "described_statsDF = {key: describe_and_enhance(df) for key, df in stats_dfs.items()}\n",
    "\n",
    "\n",
    "test_statistics = {\n",
    "    f'{key} {period}': (df, f'Mean FR Off {period.capitalize()}', f'Mean FR On {period.capitalize()}')\n",
    "    for key, df in stats_dfs.items() for period in ['early', 'late', 'spont']\n",
    "}\n",
    "\n",
    "results = {test_name: perform_analysis(*params) for test_name, params in test_statistics.items()}\n",
    "pVal_FR_DF = pd.DataFrame(results, index=['Test Statistic', 'p Value', 'Z Value', 'Effect Size'])\n",
    "pVal_FR_DF = pd.DataFrame(results).T\n",
    "pVal_FR_DF.columns = ['Test Statistic', 'p Value', 'Z Value', 'Effect Size']\n",
    "\n",
    "# Format the 'p Value' column to eight decimal places\n",
    "pVal_FR_DF['p Value'] = pVal_FR_DF['p Value'].map(lambda x: f\"{x:.8f}\")\n",
    "\n",
    "\n",
    "# Assuming described_statsDF is a dictionary of DataFrames\n",
    "for key, df in described_statsDF.items():\n",
    "    # Construct the file path for each DataFrame\n",
    "    described_statsDF_path = os.path.join(stats_dir_time, f\"StatsDF_FR_{key}_{cellType}.xlsx\")\n",
    "    # Save each DataFrame to an Excel file\n",
    "    df.to_excel(described_statsDF_path, index=True)\n",
    "\n",
    "# If you also have the pVal_FR_DF as a DataFrame\n",
    "pVal_FR_DF_path = os.path.join(stats_dir_time, f\"PVal_FR_DF_{cellType}.xlsx\")\n",
    "pVal_FR_DF.to_excel(pVal_FR_DF_path, index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming described_statsDF is a dictionary of DataFrames\n",
    "for key, df in described_statsDF.items():\n",
    "    # Construct the file path for each DataFrame\n",
    "    described_statsDF_path = os.path.join(stats_dir_time, f\"StatsDF_FR_{key}_{cellType}.csv\")\n",
    "    # Save each DataFrame to a CSV file\n",
    "    df.to_csv(described_statsDF_path, index=True)\n",
    "\n",
    "\n",
    "# If you also have the pVal_FR_DF as a DataFrame\n",
    "pVal_FR_DF_path = os.path.join(stats_dir_time, f\"PVal_FR_DF_{cellType}.csv\")\n",
    "pVal_FR_DF.to_csv(pVal_FR_DF_path, index=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"DataFrames saved to both Excel and CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Frequency Response Function </center> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "################################## Figure 5 ##############################\n",
    "##########################################################################\n",
    "\n",
    "cFR_data_info = [\n",
    "    (\"Early\", cFR, cFR_On),\n",
    "    (\"Late\", Late_cFR, Late_cFR_On),\n",
    "    (\"facil_Early\", cFR_facil, cFR_On_facil),\n",
    "    (\"facil_Late\", Late_cFR_facil, Late_cFR_On_facil),\n",
    "    (\"supp_Early\", cFR_supp, cFR_On_supp),\n",
    "    (\"supp_Late\", Late_cFR_supp, Late_cFR_On_supp)\n",
    "]\n",
    "\n",
    "# Dictionary to hold DataFrames and their descriptions\n",
    "dfs_TC = {}\n",
    "TC_described_dfs = {}\n",
    "\n",
    "# Adjust the data preparation loop to use new function\n",
    "for label, off_data, on_data in cFR_data_info:\n",
    "    dfs_TC[f'centeredOct_{label}_DF_Off'], TC_described_dfs[f'described_centeredOct_{label}_DF_Off'] = create_and_describe_df(off_data, octaves)\n",
    "    dfs_TC[f'centeredOct_{label}_DF_On'], TC_described_dfs[f'described_centeredOct_{label}_DF_On'] = create_and_describe_df(on_data, octaves)\n",
    "\n",
    "\n",
    "save_dataframes(TC_described_dfs, stats_dir_time, cellType)\n",
    "\n",
    "# Perform statistical analysis\n",
    "results_TC = {}\n",
    "for label, off_data, on_data in cFR_data_info:\n",
    "    for octave_index in range(off_data.shape[0]):\n",
    "        result_key = f\"{label} Octave {octave_index + 1}\"\n",
    "        results_TC[result_key] = perform_analysis_octaves(off_data[octave_index, :], on_data[octave_index, :])\n",
    "\n",
    "# Convert results to a DataFrame for easier viewing and manipulation\n",
    "results_df_TC = pd.DataFrame(results_TC).T\n",
    "\n",
    "results_df_TC['p Value'] = results_df_TC['p Value'].map(lambda x: f\"{x:.8f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Save results to files\n",
    "excel_path = os.path.join(stats_dir_time, f\"ResultsDF_TC_{cellType}.xlsx\")\n",
    "results_df_TC.to_excel(excel_path, index=True)\n",
    "csv_path = os.path.join(stats_dir_time, f\"ResultsDF_TC_{cellType}.csv\")\n",
    "results_df_TC.to_csv(csv_path, float_format='%.8f', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <center> Sparseness </center> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "############################ Figure 6 ####################################\n",
    "##########################################################################\n",
    "\n",
    "# Example usage with hypothetical data lists and their corresponding column names\n",
    "columns = [\n",
    "    'Sparseness Off', 'Sparseness On', 'Sparseness Off Late Tone', 'Sparseness On Late Tone',\n",
    "    'Sparseness Facilitated Off', 'Sparseness Facilitated On', 'Sparseness Facilitated Off Late Tone', 'Sparseness Facilitated On Late Tone',\n",
    "    'Sparseness Suppressed Off Tone', 'Sparseness Suppressed On Tone', 'Sparseness Suppressed Off Late Tone', 'Sparseness Suppressed On Late Tone'\n",
    "]\n",
    "data_lists = [SparsenessOff_all, SparsenessOn_all, Late_SparsenessOff_all, Late_SparsenessOn_all, SparsenessOff_facilitated, SparsenessOn_facilitated, Late_SparsenessOff_facilitated, Late_SparsenessOn_facilitated, SparsenessOff_suppressed, SparsenessOn_suppressed, Late_SparsenessOff_suppressed, Late_SparsenessOn_suppressed]\n",
    "\n",
    "\n",
    "\n",
    "data_sparseness = pad_and_create_dataframe(data_lists, columns)\n",
    "described_data_sparseness = calculate_statistics(data_sparseness)\n",
    "pairs = {\n",
    "    'Early': ('Sparseness Off', 'Sparseness On'),\n",
    "    'Late': ('Sparseness Off Late Tone', 'Sparseness On Late Tone'),\n",
    "    'Facilitated Early': ('Sparseness Facilitated Off', 'Sparseness Facilitated On'),\n",
    "    'Facilitated Late': ('Sparseness Facilitated Off Late Tone', 'Sparseness Facilitated On Late Tone'),\n",
    "    'Suppressed Early': ('Sparseness Suppressed Off Tone', 'Sparseness Suppressed On Tone'),\n",
    "    'Suppressed Late': ('Sparseness Suppressed Off Late Tone', 'Sparseness Suppressed On Late Tone'),\n",
    "}\n",
    "results_sparseness = perform_statistical_analysis(data_sparseness, pairs)\n",
    "\n",
    "\n",
    "# Convert results to a DataFrame for easier viewing and manipulation\n",
    "results_df_sparseness = pd.DataFrame(results_sparseness).T\n",
    "\n",
    "# Format p Values for better readability\n",
    "results_df_sparseness['p Value'] = results_df_sparseness['p Value'].map(lambda x: f\"{x:.8f}\")\n",
    "\n",
    "# Save results to files\n",
    "excel_path = os.path.join(stats_dir_time, f\"ResultsDF_Sparseness_{cellType}.xlsx\")\n",
    "results_df_sparseness.to_excel(excel_path, index=True)\n",
    "\n",
    "csv_path = os.path.join(stats_dir_time, f\"ResultsDF_Sparseness_{cellType}.csv\")\n",
    "results_df_sparseness.to_csv(csv_path, float_format='%.8f', index=True)\n",
    "\n",
    "# Output results to CSV\n",
    "data_sparseness.to_csv(os.path.join(stats_dir_time, f\"data_sparseness_{cellType}.csv\"), index=True)\n",
    "described_data_sparseness.to_csv(os.path.join(stats_dir_time, f\"described_data_sparseness_{cellType}.csv\"), index=True)\n",
    "results_df_sparseness.to_csv(os.path.join(stats_dir_time, f\"pVal_sparseness_DF_{cellType}.csv\"), index=True)\n",
    "\n",
    "excel_path_described = os.path.join(stats_dir_time, f\"DescribedDF_Sparseness_{cellType}.xlsx\")\n",
    "described_data_sparseness.to_excel(excel_path_described, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Time to Peak </center> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create padded DataFrames\n",
    "df_facilitated_stats = pad_and_create_dataframe(\n",
    "    [t2pOff_facil, t2pOn_facil], \n",
    "    ['Facilitated Off', 'Facilitated On']\n",
    ")\n",
    "\n",
    "df_suppressed_stats = pad_and_create_dataframe(\n",
    "    [t2pOff_supp, t2pOn_supp], \n",
    "    ['Suppressed Off', 'Suppressed On']\n",
    ")\n",
    "\n",
    "# Convert times from seconds to milliseconds (if needed)\n",
    "df_facilitated_stats *= 1000\n",
    "df_suppressed_stats *= 1000\n",
    "\n",
    "\n",
    "# Calculate descriptive statistics for both DataFrames\n",
    "stats_facilitated = calculate_statistics(df_facilitated_stats)\n",
    "stats_suppressed = calculate_statistics(df_suppressed_stats)\n",
    "\n",
    "\n",
    "\n",
    "# Set pairs for the Wilcoxon test\n",
    "pairs_facilitated = {\n",
    "    'Facilitated Off vs On': ('Facilitated Off', 'Facilitated On')\n",
    "}\n",
    "pairs_suppressed = {\n",
    "    'Suppressed Off vs On': ('Suppressed Off', 'Suppressed On')\n",
    "}\n",
    "\n",
    "# Perform Wilcoxon tests\n",
    "results_facilitated = perform_statistical_analysis(df_facilitated_stats, pairs_facilitated)\n",
    "results_suppressed = perform_statistical_analysis(df_suppressed_stats, pairs_suppressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filenames for facilitated results\n",
    "facilitated_stats_excel = os.path.join(stats_dir_time, f\"DescribedDF_T2P_Facilitated_{cellType}.xlsx\")\n",
    "facilitated_stats_csv = os.path.join(stats_dir_time, f\"DescribedDF_T2P_Facilitated_{cellType}.csv\")\n",
    "\n",
    "facilitated_analysis_excel = os.path.join(stats_dir_time, f\"ResultsDF_T2P_Facilitated_{cellType}.xlsx\")\n",
    "facilitated_analysis_csv = os.path.join(stats_dir_time, f\"ResultsDF_T2P_Facilitated_{cellType}.csv\")\n",
    "\n",
    "# Save facilitated stats to Excel and CSV\n",
    "stats_facilitated.to_excel(facilitated_stats_excel, index=True)\n",
    "stats_facilitated.to_csv(facilitated_stats_csv, float_format='%.8f', index=True)\n",
    "\n",
    "# Save facilitated analysis to Excel and CSV\n",
    "results_facilitated.to_excel(facilitated_analysis_excel, index=True)\n",
    "results_facilitated.to_csv(facilitated_analysis_csv, float_format='%.8f', index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define filenames for suppressed results\n",
    "suppressed_stats_excel = os.path.join(stats_dir_time, f\"DescribedDF_T2P_Suppressed_{cellType}.xlsx\")\n",
    "suppressed_stats_csv = os.path.join(stats_dir_time, f\"DescribedDF_T2P_Suppressed_{cellType}.csv\")\n",
    "\n",
    "suppressed_analysis_excel = os.path.join(stats_dir_time, f\"ResultsDF_T2P_Suppressed_{cellType}.xlsx\")\n",
    "suppressed_analysis_csv = os.path.join(stats_dir_time, f\"ResultsDF_T2P_Suppressed_{cellType}.csv\")\n",
    "\n",
    "# Save suppressed stats to Excel and CSV\n",
    "stats_suppressed.to_excel(suppressed_stats_excel, index=True)\n",
    "stats_suppressed.to_csv(suppressed_stats_csv, float_format='%.8f', index=True)\n",
    "\n",
    "# Save suppressed analysis to Excel and CSV\n",
    "results_suppressed.to_excel(suppressed_analysis_excel, index=True)\n",
    "results_suppressed.to_csv(suppressed_analysis_csv, float_format='%.8f', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
